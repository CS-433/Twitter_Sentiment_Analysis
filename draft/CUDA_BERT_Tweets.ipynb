{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCYYUCwVyAHB"
   },
   "source": [
    "This notebook is heavily inspired by https://towardsdatascience.com/build-a-bert-sci-kit-transformer-59d60ddd54a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YxF7HI1W4u3v"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sDBG-UenSK48"
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-BrK3x_E1CzH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7OgJPTFLz-T"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570,
     "referenced_widgets": [
      "1acd8910b26b42e68a89ef73f8280c5a",
      "ef4026c04d0d49f1aedf42fa97ef0dc6",
      "8b0d40bc6e3449a5adc6bb4abeafcf2c",
      "f46329a657d4437681d54c5dc244867b",
      "fd40c0fad38c44558b8bf14399cf5ce9",
      "f02d8d332daa46449a6d556f7eebd2e7",
      "330cb9a48e7e4e2e90b6630e902494e3",
      "e2fa89d6534d4baea5de49db4fc3f9fd"
     ]
    },
    "id": "AAJTLBDS44VS",
    "outputId": "1aa1e015-5757-4a0e-e1d0-9f8f4a13e946"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Matteo/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at C:\\Users\\Matteo/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at C:\\Users\\Matteo/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'very', 'long', 'word', 'un', '##k']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize(\"this is a very long word UNK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [UNK] [SEP]'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(bert_tokenizer.encode(\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'long',\n",
       " 'word',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'hash',\n",
       " '##tag']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize([\"this\", \"is\", \"a\", \"very\", \"long\", \"word\", \"and\", \"this\", \"is\", \"an\", \"hashtag\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoding = bert_tokenizer.encode([\"thi   s\", \"is\", \"a\", \"very\", \"long\", \"word\", \"and\", \"this\", \"is\", \"an\", \"hashtag\"], is_split_into_words=True)\n",
    "#test_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomorrow', ',', 'i', \"'\", 'll', 'do', 'that']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize(\"tomorrow, i'll do that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from here: https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
    "contractions = { \n",
    "\"ain't\": \"be not\", # \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"be not\", # \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\", # \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\", # \"he shall / he will\",\n",
    "\"he's\": \"he is\", # \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"howdy\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how\", # \"how has / how is / how does\",\n",
    "\"i'd\": \"i would\", # \"I had / I would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\", # \"I shall / I will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\", # \"it had / it would\",\n",
    "\"it'll\": \"it will\", # \"it shall / it will\",\n",
    "\"it's\": \"it is\", # \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\", # \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\", # \"she shall / she will\",\n",
    "\"she's\": \"she is\", # \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that's\": \"that is\", # \"that has / that is\",\n",
    "\"there's\": \"there is\", # \"there has / there is\",\n",
    "\"they'd\": \"they would\", # \"they had / they would\",\n",
    "\"they'll\": \"they will\", # \"they shall / they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\", # \"we had / we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what's\": \"what is\", # \"what has / what is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\", # \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\", # \"who shall / who will\",\n",
    "\"who's\": \"who is\", # \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\", # \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"y'all\": \"you all\",\n",
    "\"you'd\": \"you would\", # \"you had / you would\",\n",
    "\"you'll\": \"you will\", # \"you shall / you will\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be not'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions[\"ain't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence_array, purge_methods):\n",
    "    for method in purge_methods:\n",
    "        sentence_array = method(sentence_array)\n",
    "    return sentence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_hashtag(before):\n",
    "    if len(before) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    if before[0] == \"#\":\n",
    "        return before[1:]\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contractions(before):\n",
    "    if before in contractions:\n",
    "        return contractions[before]\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_end_of_line(before):\n",
    "    if len(before) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    if before[-1] == '\\n':\n",
    "        return before[:-1]\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_tags(before):\n",
    "    if before == \"<url>\":\n",
    "        return \"[UNK]\"\n",
    "    elif before == \"xox\":\n",
    "        return \"kiss\"\n",
    "    elif before == \"<user>\":\n",
    "        return \"alice\"\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_method(lmt_wise_method):\n",
    "    return np.vectorize(lmt_wise_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<user>', \"don't\", 'go', 'offline', 'xxx\\n'], dtype='<U7')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_data[4565].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alice', 'do not', 'go', 'offline', 'xxx'], dtype='<U7')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_sentence(np.array(train_data[4565].split(\" \")), [to_method(remove_end_of_line), to_method(remove_hashtag), to_method(remove_contractions), to_method(words_to_tags)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_file = []\n",
    "with open(\"twitter-datasets/train_pos_full_u.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        big_file.append(np.array(line.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_file_proc = []\n",
    "for sentence in big_file:\n",
    "    big_file_proc.append(process_sentence(sentence, [to_method(remove_end_of_line), to_method(remove_hashtag), to_method(remove_contractions), to_method(tags_to_unk)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['!', '!', '!', '!', '!', '!', 'rt', '<user>', 'free', 'coldstones',\n",
       "        'for', 'me', 'and', 'the', 'girls', 'i', 'could', 'get', 'use',\n",
       "        'to', 'this', 'heaven'], dtype='<U10'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'gemini', 'are', 'entertaining', '.',\n",
       "        'ever', 'have', 'one', 'in', 'bed', '?', 'try', 'it', '\"'],\n",
       "       dtype='<U12'),\n",
       " array(['!', '!', '!', '\"', '<user>', \"idontf'ckwitchu\", 'cause', 'you',\n",
       "        'think', 'i', 'want', 'your', 'man', 'but', 'really', 'he',\n",
       "        'wants', 'me', '\"'], dtype='<U15'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'np', 'fun', '-', 'we', 'are',\n",
       "        'young', '...', 'i', 'that', 'song', '!', 'idc', 'what', 'anyone',\n",
       "        'says', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'sagittarius', 'are', 'extremely',\n",
       "        'turned', 'on', 'by', 'aggressive', 'lovers', '!', '\"'],\n",
       "       dtype='<U11'),\n",
       " array(['!', '!', '!', '\"', '<user>', '<user>', 'hey', 'i', 'think', 'you',\n",
       "        'should', 'go', 'blonde', 'again', '!', 'just', 'a', 'suggestion',\n",
       "        '\"'], dtype='<U10'),\n",
       " array(['!', '!', '!', '\"', '<user>', '<user>', 'i', 'love', 'your',\n",
       "        'tweets', ',', 'they', 'inspires', 'me', ',', 'they', 'make', 'my',\n",
       "        'day', ',', 'keep', 'up', 'the', 'positive', 'energy', '\"'],\n",
       "       dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', '<user>', 'i', 'might', 'come', 'as',\n",
       "        'a', 'friend', 'but', 'baby', 'i', 'will not', 'leave', 'as', 'a',\n",
       "        'friend', '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', '<user>', 'just', 'wanted', 'to',\n",
       "        'tell', 'you', 'your', 'amazing', '.', '<3', '\"'], dtype='<U7'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'all', 'hail', 'google', 'rt',\n",
       "        '<user>', 'sex', 'burns', '25.7', 'calories', 'per', 'minute', ',',\n",
       "        'with', 'that', 'being', 'said', ',', 'wanna', 'work', 'out', '?',\n",
       "        '\"', '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'basketball', 'shorts', 'always',\n",
       "        'grab', 'my', 'attention', '.', '\"'], dtype='<U10'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'cause', 'its', 'not', 'cool', '\"',\n",
       "        '<user>', 'why', '?', '?', 'rt', '\"', '<user>', 'for', 'babes',\n",
       "        'to', 'smoke', 'be not', 'so', 'cool', 'you', 'know', '.', ':|',\n",
       "        '\"', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'he', 'turned', 'it', '-', 'ricky',\n",
       "        'dillard', '\"'], dtype='<U7'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'hmmph', 'not', 'me', '!',\n",
       "        'everybody', 'thats', 'knows', 'me', 'knows', 'i', 'dont', 'smoke',\n",
       "        '\"'], dtype='<U9'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'i', 'hate', 'bitches', 'less',\n",
       "        'talk', 'move', 'them', 'hands', 'be not', 'about', 'that', 'life',\n",
       "        'i', 'see', '\"'], dtype='<U7'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'i', 'hate', 'when', 'females',\n",
       "        'say', '\"', 'suck', 'my', 'dick', '\"', 'like', 'listen', 'bitch',\n",
       "        'you', 'dont', 'have', 'a', 'dick', 'choke', 'on', 'one', '\"'],\n",
       "       dtype='<U7'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'i', 'have', 'this', 'secret',\n",
       "        'obsession', 'with', 'elbows', '...', '\"', 'omg', '.', 'me',\n",
       "        'tooo', '.', ')'], dtype='<U9'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'i', 'love', 'when', 'a', 'guy',\n",
       "        'does', 'sweet', 'simple', 'things', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'im', 'really', 'not', 'the', 'one',\n",
       "        'loll', '.', 'everyone', 'got', 'me', 'all', 'fucked', 'up', 'so',\n",
       "        'ill', 'give', 'yu', 'a', 'reason', 'to', 'tlk', 'loll', 'haaa',\n",
       "        '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'me', ',', 'myself', ',', '&', 'i',\n",
       "        '>', '>', '>', 'that', 'song', 'will', 'never', 'get', 'old', '\"'],\n",
       "       dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'my', 'birthday', 'in', '12', 'days',\n",
       "        'we', 'in', 'nyc', 'tearin', 'shit', 'up', 'with', 'my', 'girls',\n",
       "        'lol', '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'people', 'always', 'have',\n",
       "        'something', 'to', 'say', 'about', 'me', ',', 'but', 'never', 'to',\n",
       "        'me', '.', '\"'], dtype='<U9'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'retentive', 'memory', 'is', 'all',\n",
       "        'i', 'ask', 'for', 'o', 'lord', 'o', '\"'], dtype='<U9'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'roll', 'his', 'weed', 'up', 'and',\n",
       "        'i', 'do not', 'even', 'smoke', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'sex', 'is', 'on', 'my', 'mind', '\"'],\n",
       "       dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'shalom', 'has', 'fans', 'though',\n",
       "        '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'spring', 'break', 'starts',\n",
       "        'tomorrow', '@', '2:35', ')', ')', ')', 'helll', 'yesss', '\"'],\n",
       "       dtype='<U8'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'that', 'text', 'i', 'just', 'sent',\n",
       "        '<user>', 'lmao', '!', '!', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'the', 'lady', 'at', 'mcdonalds',\n",
       "        'said', 'she', 'like', 'my', 'green', 'braces', '&', 'tattoos',\n",
       "        'so', ',', 'she', 'gave', 'me', 'some', 'free', 'apple', 'pies',\n",
       "        ',', 'lmmfao', '\"'], dtype='<U9'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'there', 'are', 'a', 'lot', 'of',\n",
       "        'april', 'babies', 'though', '..', 'wer', 'too', 'cool', '...',\n",
       "        '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'we', 'climax', 'at', 'the', 'same',\n",
       "        'time', '.', '!', 'best', 'sex', 'ever', '.', '!', '!', '*',\n",
       "        'high', 'five', '*', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'with', 'who', '?', 'rt', '<user>',\n",
       "        'am', 'in', 'love', '!', 'sarah', 'is', 'in', 'love', ',', 'am',\n",
       "        'in', 'love', 'wohoo', '!', '!', '!', ':', '*', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', '\"', '<user>', 'yesss', 'bew', '.', 'rt', '<user>',\n",
       "        'wtf', 'is', 'a', 'nique', '?', 'i', 'only', 'love', '<user>', ',',\n",
       "        '<user>', '&', '<user>'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'dailytweet', ',', 'cause', 'that is', 'all',\n",
       "        'dese', 'niggas', 'do', '..', 'llsrt', '<user>', 'i', 'love',\n",
       "        'the', 'way', 'you', 'lie'], dtype='<U10'),\n",
       " array(['!', '!', '!', 'iknowwhatyoumean', 'it will', 'all', 'work',\n",
       "        'itself', 'out', 'deacon', '<3', 'rt', '<user>', 'having',\n",
       "        'answers', 'to', 'everyones', \"'\", 'situations', 'but', \"your's\",\n",
       "        '.', '<', '<', '<'], dtype='<U16'),\n",
       " array(['!', '!', '!', '&', 'lived', 'next', 'door', 'rt', '<user>', 'i',\n",
       "        'wished', 'oomf', 'went', 'to', 'my', 'school', ','], dtype='<U6'),\n",
       " array(['!', '!', '!', \"'\", '!', '!', '!', 'lol', '\"', '<user>', 'i',\n",
       "        'like', 'the', 'way', 'he', 'like', 'the', 'way', 'my', 'cum',\n",
       "        'taste', 'c', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', ')', ')', ')', 'rt', '<user>', '<user>', '<user>',\n",
       "        '<user>', '<user>', 'did', 'tyler', 'just', 'compliment',\n",
       "        'cheyenne', '?', 'what', '?', 'what', 'is', 'life', '?'],\n",
       "       dtype='<U10'),\n",
       " array(['!', '!', '!', ')', 'rt', '<user>', 'i', 'cannot', 'wait', 'to',\n",
       "        'meet', 'my', 'new', 'teammates', 'for', 'next', 'year', '!',\n",
       "        'excited'], dtype='<U9'),\n",
       " array(['!', '!', '!', '->', 'rt', '<user>', '<user>', '<user>', 'okay',\n",
       "        '.', 'i', 'like', 'dolly', 'parton', '.', '.', 'but', 'she',\n",
       "        'aint', 'getting', 'anymore', 'nominations', 'bey', 'still',\n",
       "        'will', '.'], dtype='<U11'),\n",
       " array(['!', '!', '!', '.', 'rt', '<user>', 'ayye', 'april', '18', 'and',\n",
       "        'spr', '10', '2/2', 'rt', '<user>', 's', '/', 'o', 'to', 'all',\n",
       "        'my', 'spr', \"'\", '10', 'sandz', '!', '!', '!', '2yrs', 'in', '..',\n",
       "        'and', 'a', 'lifetime', 'to', 'go', '!', '!', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', ':', '-', '*', 'rt', '<user>', 'still', 'eating',\n",
       "        'easter', 'candy', '<user>', 'gave', 'me', '...', 'fatty',\n",
       "        'sweettooth', '[UNK]'], dtype='<U10'),\n",
       " array(['!', '!', '!', '<user>', '\"', '<user>', 'walmart', 'with', 'eddie',\n",
       "        '&', 'rose', '\"', 'you', 'always', 'in', 'walmart'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', '.', 'tomorrow', 'imma', 'smoke', 'a',\n",
       "        'box', 'of', 'blunts', 'for', 'breakfast', ')', 'ayee', '\"', '!',\n",
       "        '!'], dtype='<U9'),\n",
       " array(['!', '!', '!', '<user>', '<user>', '\"', '<user>', '<user>', 'is',\n",
       "        'wifey', 'material', '\"', 'pop', 'the', 'question', 'then',\n",
       "        'cuhhh', 'lol'], dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', '<user>', 'virgo', 'females', 'have',\n",
       "        'the', 'best', 'lips', '...', 'you', 'know', 'what', 'i', 'mean',\n",
       "        '.'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', '<user>', 'my', 'bestfriend', 'is', 'the',\n",
       "        'best', '!', '!', '!'], dtype='<U10'),\n",
       " array(['!', '!', '!', '<user>', 'and', 'i', 'have', 'nobody'], dtype='<U6'),\n",
       " array(['!', '!', '!', '<user>', 'diamonds', 'are', 'forever', ',', 'i am',\n",
       "        'his', 'bitch', 'forever', 'i', 'had', 'his', 'back', 'forever',\n",
       "        'he', 'was', 'in', 'that', 'trap', 'forever', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'excuse', 'my', 'lito', 'mama', ',',\n",
       "        'but', 'you', 'can', 'say', 'i am', 'on', 'duty', '.', 'i am',\n",
       "        'lookin', 'for', 'a', 'cutie', ',', 'a', 'real', 'big', 'ol', \"'\",\n",
       "        'ghetto', 'booty', '.'], dtype='<U6'),\n",
       " array(['!', '!', '!', '<user>', 'fucked', 'yo', 'girl', 'lastnight', ',',\n",
       "        'it', 'only', 'took', 'a', 'tweet'], dtype='<U9'),\n",
       " array(['!', '!', '!', '<user>', 'happy', 'birthday', 's', '/', 'o', 'to',\n",
       "        'the', 'beautiful', '<user>', '!', '!'], dtype='<U9'),\n",
       " array(['!', '!', '!', '<user>', 'hmm', ',', 'thinkk', 'i am', 'gonnaa',\n",
       "        'ignoree', 'everyone', 'but', 'him', 'tonitee', '..'], dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'i', 'seen', '<user>', 'today', 'omg',\n",
       "        'i', 'missed', 'her'], dtype='<U6'),\n",
       " array(['!', '!', '!', '<user>', 'i', 'was', 'happy', 'to', 'see',\n",
       "        '<user>', 'today', 'i', 'was', 'even', 'more', 'happy', 'i', 'saw',\n",
       "        'you'], dtype='<U6'),\n",
       " array(['!', '!', '!', '<user>', 'its', 'a', 'beautiful', 'thing', '\"',\n",
       "        '<user>', 'i', 'have', 'my', 'life', ',', 'health', ',', 'and',\n",
       "        'strength', '...', 'so', 'i am', 'maintaining', '...', ')', '\"'],\n",
       "       dtype='<U11'),\n",
       " array(['!', '!', '!', '<user>', 'my', 'audri', 'pooh', 'got', 'her',\n",
       "        'ears', 'pierced', 'today', '[UNK]'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', 'my', 'tl', ',', 'my', 'twitter', ',',\n",
       "        'my', 'mentions', ',', 'my', 'tweets', '...', 'do not', 'like',\n",
       "        'what', 'yu', 'see', ':', 'we will', 'bitch', 'unfollow', 'me'],\n",
       "       dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'okay', ',', 'it', 'is', 'time', 'for',\n",
       "        'more', 'tattoos', '.'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', 'pressing', 'the', 'middle', 'of', 'your',\n",
       "        'amala', 'and', 'pouring', 'your', 'soup', 'there', '.', 'yikess',\n",
       "        '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'read', 'this', 'rt', '\"', '<user>', 'if',\n",
       "        'she', 'puts', 'up', 'with', 'your', 'bull', 'and', 'willing',\n",
       "        'to', 'forgive', 'you', 'then', 'she is', 'a', 'keeper', '\"'],\n",
       "       dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', \"s'o\", 'to', 'my', '<user>', '...',\n",
       "        'she is', 'the', 'best', '..', 'real', 'talk', '...', 'love',\n",
       "        'her', 'to', 'death', '.', 'go', 'follow', 'her', 'a', '*', '*',\n",
       "        'though'], dtype='<U6'),\n",
       " array(['!', '!', '!', '<user>', 'seeing', 'my', 'name', 'on', 'the',\n",
       "        'perfect', 'attendance', 'board', 'made', 'my', 'day', '.'],\n",
       "       dtype='<U10'),\n",
       " array(['!', '!', '!', '<user>', 'seen', 'my', 'bff', '<user>', 'at',\n",
       "        'the', 'mall', 'today', '...', 'bigmoney', '!', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'they', 'still', 'checking', 'for', 'me'],\n",
       "       dtype='<U8'),\n",
       " array(['!', '!', '!', '<user>', 'uggg', 'lol', 'rt', '<user>', 'every',\n",
       "        'once', 'in', 'a', 'while', 'i', 'like', 'to', 'pretend', 'like',\n",
       "        'i am', 'keeping', 'up', 'with', 'sports'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', 'wanna', 'go', 'to', 'the', 'movies',\n",
       "        'tonight'], dtype='<U7'),\n",
       " array(['!', '!', '!', '<user>', 'yay', 'her', 'baby', 'coming', 'on',\n",
       "        'here', 'bday', '<user>'], dtype='<U6'),\n",
       " array(['!', '!', '!', '?', '?', '?', 'i', 'feel', 'weird', 'inside',\n",
       "        'like', \"butterfly's\"], dtype='<U11'),\n",
       " array(['!', '!', '!', 'amen', 'rt', '<user>', 'thats', 'the', 'best', '!',\n",
       "        '!', '!', 'its', 'my', 'favorite', 'rt', '<user>', 'yay', '!',\n",
       "        '<user>', 'dips', 'her', 'chicken', 'fingers', 'in', 'her',\n",
       "        'frosty', 'lik', 'mee', ')', '!', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'beautiful', 'bby', 'nvr', 'seen', 'you', 'w', '/',\n",
       "        'o', '&', 'by', 'george', 'i', \"like's\", 'it', '!', '<user>', 'no',\n",
       "        'make-up', 'bby', '!', 'straight', 'up', ':', '-', '*', '[UNK]'],\n",
       "       dtype='<U9'),\n",
       " array(['!', '!', '!', 'but', 'are', 'they', 'just', 'exes', 'nje', '?',\n",
       "        '?', '^', '.', '^', ')', '>', 'rt', '<user>', 'ncaaaw', '<user>',\n",
       "        'ex', 'is', 'so', 'gorge'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'ever', '.', 'thatisall', 'rt', '<user>', 'do not',\n",
       "        'ever', 'get', 'too', 'comfortable'], dtype='<U11'),\n",
       " array(['!', '!', '!', 'every', 'relationships', 'gonna', 'have', 'its',\n",
       "        'ups', '&', 'downs', ',', 'but', 'it', 'takes', 'a', 'real',\n",
       "        'relationship', 'to', 'go', 'thru', 'shit', '&', 'still', 'be',\n",
       "        'around'], dtype='<U13'),\n",
       " array(['!', '!', '!', 'feeling', 'the', 'same', 'way', '.', 'rt',\n",
       "        '<user>', 'i', 'got', 'some', '$', '$', '$', 'for', 'anyone',\n",
       "        'who is', 'tryin', \"'\", 'to', 'do', 'this', 'paper', 'for', 'me'],\n",
       "       dtype='<U7'),\n",
       " array(['!', '!', '!', 'going', 'to', 'follow', 'next', '10ppl', 'to',\n",
       "        'follow', '!', '!', '!', '>', '>', '>', '<user>', 'for', 'me', ',',\n",
       "        'so', 'hurry', 'up'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'i', 'look', 'little', 'on', 'i', 'am', '.', 'lol',\n",
       "        '\"', '<user>', 'me', 'an', 'my', 'stanka', '<user>', ',', 'having',\n",
       "        'heart', 'to', 'heart', '[UNK]'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'i am', 'glad', 'peeps', 'are', 'appreciating',\n",
       "        'her', 'talent', 'rt', '<user>', 'loving', 'the', 'voice', 'of',\n",
       "        'emeli', 'sande', '...'], dtype='<U12'),\n",
       " array(['!', '!', '!', 'im', 'here', '\"', '<user>', 'i', 'wish', 'oomf',\n",
       "        'get', 'off', 'twitter', '&', 'bring', 'his', 'cripple', 'ass',\n",
       "        'to', 'school', 'lol', '\"'], dtype='<U7'),\n",
       " array(['!', '!', '!', 'lets', 'go', '!', 'rt', '<user>', 'poly', 'lax',\n",
       "        'is', 'gonna', 'win', 'today', ',', 'both', 'boys', 'and', 'girls',\n",
       "        '.', 'goodluck'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'lmfao', 'rt', '<user>', 'ikr', ',', 'yall',\n",
       "        'remember', 'my', '13', 'bday', 'in', 'my', 'backyard', '!', '!',\n",
       "        '!', 'lmao', ',', 'we', 'was', 'getting', 'dowin', 'in', 'the',\n",
       "        'dirt', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'lol', '\"', '<user>', 'when', 'normal', 'people',\n",
       "        'see', 'a', 'couple', ':', '\"', 'aw', ',', 'they', 'soo', 'cute',\n",
       "        'together', '.', '\"', 'me', ':', '\"', 'i', 'wonder', 'do', 'they',\n",
       "        'be', 'doing', 'it', '..', '\"', 'lol', '.', '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'lol', 'rt', '<user>', 'i', 'think', 'it is', 'so',\n",
       "        'cute', 'how', 'steph', 'and', 'david', 'are', 'a', 'couple',\n",
       "        \":')\", 'i', 'knew', 'he', 'always', 'had', 'a', 'thing', 'for',\n",
       "        'her'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'lol', 'rt', '<user>', 'relationship', 'season',\n",
       "        'is', 'over', 'hellooo', 'summer'], dtype='<U12'),\n",
       " array(['!', '!', '!', 'me', 'tooo', 'mnn', '\"', '<user>', 'i', 'love',\n",
       "        'ppl', 'who', 'subtweet', 'me', '&', 'dnt', 'even', 'follow', 'me',\n",
       "        '.', '\"'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'must', 'happen', '\"', '<user>',\n",
       "        'thingsimustdothissummer', 'have', 'another', 'adventure', 'with',\n",
       "        '<user>', 'and', '<user>', '\"'], dtype='<U23'),\n",
       " array(['!', '!', '!', 'omg', 'i', 'am', 'so', 'happy', '!', 'my', 'life',\n",
       "        'is', 'really', 'turning', 'arounddd', '!', '!', '!'], dtype='<U8'),\n",
       " array(['!', '!', '!', 'proud', 'of', 'you', 'rt', '<user>', 'swaggin',\n",
       "        '[UNK]'], dtype='<U7'),\n",
       " array(['!', '!', '!', 'pussy', 'money', 'weed', 'rt', '<user>', 'and',\n",
       "        'when', 'she is', 'butt', 'naked', 'she is', 'dressed', 'to',\n",
       "        'kill'], dtype='<U7'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', '<user>', '<user>', 'kell',\n",
       "        'stop', 'fuccin', 'wit', 'my', 'sister', '!', 'b4', 'i', 'hurt',\n",
       "        'you', '..', 'frfr', '!'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'bitches', 'in', 'love',\n",
       "        'with', 'my', 'nigga', 'and', 'it', 'feels', 'good', 'because',\n",
       "        'he', 'only', 'loving', 'me', '\"'], dtype='<U7'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'girlfriend', ':', 'babe', ',',\n",
       "        'whats', 'your', 'favorite', 'position', '?', 'boyfriend', ':',\n",
       "        'when', 'i', 'get', 'on', 'one', 'knee', 'and', 'make', 'you',\n",
       "        'my', 'wife', '.', '\"'], dtype='<U10'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'her', 'name', 'is', 'kaylah',\n",
       "        '!', 'and', 'do not', 'forget', 'the', \"'\", 'h', \"'\", 'on', 'the',\n",
       "        'end', '!', 'that is', 'rns', '...', '\"', 'ayeee', '!'],\n",
       "       dtype='<U7'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'its', 'the', 'dick', 'game',\n",
       "        'really', ',', 'why', 'she', 'like', 'to', 'get', 'popped', '!',\n",
       "        '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'keep', 'talkin', ',', 'keep',\n",
       "        'hatin', ',', 'keep', 'trying', 'to', 'stop', 'me', '-', 'tha',\n",
       "        'shit', 'not', 'gone', 'work', '\"'], dtype='<U6'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'ppl', 'dnt', 'understand',\n",
       "        'me', 'but', 'that is', 'what', 'i', 'like', '\"'], dtype='<U10'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'that is', 'an',\n",
       "        'understatement', 'rt', '<user>', 'very', 'pretty', '!', 'rt',\n",
       "        '<user>', 'you are', 'pretty', '<user>'], dtype='<U14'),\n",
       " array(['!', '!', '!', 'rt', '\"', '<user>', 'you', 'do not', 'have', 'to',\n",
       "        'have', 'a', 'fake', 'ass', 'or', 'a', 'flat', 'stomach', 'or',\n",
       "        'big', 'tits', 'to', 'be', 'beautiful', 'ladies', 'remember',\n",
       "        'that', '!', '!', '!', ')', ')', '\"'], dtype='<U9'),\n",
       " array(['!', '!', '!', 'rt', '<user>', 'honesthour', 'i', 'love', 'lip',\n",
       "        'biting', ',', 'and', 'neck', 'kisses'], dtype='<U10'),\n",
       " array(['!', '!', '!', 'rt', '<user>', 'lethirst', 'rt', '<user>', 'these',\n",
       "        'boys', 'at', 'walmart', '>', '>', '>', 'omg', ')', ')', ')'],\n",
       "       dtype='<U8')]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_file_proc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', '##ox', 'kiss']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize((\"xox  kiss\").split(\" \"), is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2019, 2023, 2483, 29337, 2773, 102]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.encode([\"an\", \"thisisyou\", \"\", \"word\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] an thisisyou word [SEP]'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode([101, 2019, 2023, 2483, 29337, 2773, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', '##is', '##you']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize(\"thisisyou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622,
     "referenced_widgets": [
      "06f0b42426d3413a82961fe268ea9784",
      "3c9ae8f1d48444b181b2649010162d02",
      "dfaac1d07aae40cfa8dc1eaf4d05f4bb",
      "727b19a4811447afb5e0186b5fc53957",
      "801d15e2514c482a8b2b5b7afd451896",
      "65fca3e9d79348afbf88c4e4d01d173c",
      "5bf48da7a56b44918760c102f61ba13c",
      "36a42715763d4686a65ca65020cbab18"
     ]
    },
    "id": "WMkwtsSC6Csd",
    "outputId": "ae572603-15d2-41c6-c070-d25389c8de5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at C:\\Users\\Matteo/.cache\\huggingface\\transformers\\23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Matteo/.cache\\huggingface\\transformers\\9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "All model checkpoint weights were used when initializing DistilBertModel.\n",
      "\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "i2XefgNT1JVp"
   },
   "outputs": [],
   "source": [
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_tokenizer,\n",
    "            bert_model,\n",
    "            max_length: int = 60,\n",
    "            embedding_func: Optional[Callable[[torch.tensor], torch.tensor]] = None,\n",
    "            truncate = True,\n",
    "    ):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "\n",
    "        # TODO: Handle case with CPU only\n",
    "        self.device = torch.device('cuda:0')\n",
    "\n",
    "        self.model = bert_model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.truncate = truncate\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0].cpu()[:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text: str) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        # Tokenize the text with the provided tokenizer\n",
    "        tokenized_text = self.tokenizer.encode_plus(\n",
    "                          text,\n",
    "                          add_special_tokens=True,\n",
    "                          max_length=self.max_length,\n",
    "                          truncation=self.truncate,\n",
    "                          is_split_into_words=True,\n",
    "                        )[\"input_ids\"]\n",
    "\n",
    "        # Create an attention mask telling BERT to use all words\n",
    "        attention_mask = [1] * len(tokenized_text)\n",
    "\n",
    "        # bert takes in a batch so we need to unsqueeze the rows\n",
    "        return (\n",
    "            torch.tensor(tokenized_text).unsqueeze(0),\n",
    "            torch.tensor(attention_mask).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def _tokenize_and_predict(self, text: str) -> torch.tensor:\n",
    "        tokenized, attention_mask = self._tokenize(text)\n",
    "\n",
    "        # TODO: Handle case with CPU only\n",
    "        tokenized_gpu = tokenized.to(self.device)\n",
    "        attention_mask_gpu = attention_mask.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model(tokenized_gpu, attention_mask_gpu)\n",
    "        return self.embedding_func(embeddings)\n",
    "\n",
    "    def transform(self, text: List[str]):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "\n",
    "        ## TODO: Debug (Should change it when finetuning)\n",
    "        self.model.eval()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            return torch.stack([self._tokenize_and_predict(string) for string in text])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting necessary so we just return ourselves\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SmJeHXSIL3sU"
   },
   "outputs": [],
   "source": [
    "rng = RandomState(124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlMYxKEh36ic"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X6v4fUY04WjI"
   },
   "outputs": [],
   "source": [
    "neg_train = []\n",
    "with open(\"twitter-datasets/train_neg_u.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        neg_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c4rsAd4MD0j8"
   },
   "outputs": [],
   "source": [
    "pos_train = []\n",
    "with open(\"twitter-datasets/train_pos_u.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        pos_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9Ik30qoDTZB",
    "outputId": "18e381bc-05db-404e-c26b-1e7969d490ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91088, 90233)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train), len(pos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING: I get rid of some negative samples to re-establish class equilibrium\n",
    "Imbalanced classes are a pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_train = neg_train[:len(pos_train)-len(neg_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90233"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkTtCLBmxStp"
   },
   "source": [
    "#### Trim the dataset used for training\n",
    "Right now, I only use 5K samples from each category to test the training\n",
    "(17mins to train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8W2gXvm0xeHh"
   },
   "outputs": [],
   "source": [
    "samples_num_by_cat = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "euNoeET9e07T"
   },
   "outputs": [],
   "source": [
    "neg_train = neg_train[:samples_num_by_cat]\n",
    "pos_train = pos_train[:samples_num_by_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cmmBj-UpHL8s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([[0] * len(neg_train), [1] * len(pos_train)])\n",
    "\n",
    "train_data = np.concatenate([neg_train, pos_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZlpxdtqK_tu",
    "outputId": "42da3b13-02e3-4f72-fef4-bc01e9243c72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffling = np.arange(0, train_data.shape[0])\n",
    "len(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CmBQ5G89L8-G"
   },
   "outputs": [],
   "source": [
    "rng.shuffle(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lmgYUmgbMAFZ"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[shuffling]\n",
    "train_data = train_data[shuffling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = []\n",
    "for sentence in train_data:\n",
    "    train_tokenized.append(process_sentence(np.array(sentence.split(\" \")), [to_method(remove_end_of_line), to_method(remove_hashtag), to_method(remove_contractions), to_method(words_to_tags)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd-06Pm13-gQ"
   },
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKRE_TZAGs7F"
   },
   "source": [
    "#### Take care of strange tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "UQh4UxzGE6ti"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-119b43ff0e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstrange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(<[^(<|\\s|3]*?>)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstrange\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mstrange\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "strange = set()\n",
    "for el in train_data:\n",
    "    for spec in re.findall(\"(<[^(<|\\s|3]*?>)\", el):\n",
    "        if spec not in strange:\n",
    "            strange.add(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGEtHJDnHBTz",
    "outputId": "3bb88149-89da-4717-bf74-3fbd9938916c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "2mZ0IvZdJYV_"
   },
   "outputs": [],
   "source": [
    "# Skip for now\n",
    "# purified_train = []\n",
    "# for tp in train_data:\n",
    "#   for st in strange:\n",
    "#     purified_train.append(tp.replace(st, \"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "AFzK71I-D9J6"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(zip(train_labels, train_data), columns=[\"emotion\", \"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "liDl3DvQEORZ",
    "outputId": "bf595f1e-9ce1-48ff-cde2-d7feb538f900"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, hey, baby, ,, you, wanna, pick, me, up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[alive, in, south, africa, (, audio, cd, get, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[alice, i, actually, am, he, said, lutons, too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, alice, these, glasses, are, very, nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[alice, please, folback, this, fanbase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79995</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, alice, of, course, !, i, follow, you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79996</td>\n",
       "      <td>0</td>\n",
       "      <td>[alice, -, he, wont, eat, or, drink, and, when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79997</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, no, prob, ., good, luck, !, you are, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79998</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, sorry, ,, earth, day, is, the, 22nd, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79999</td>\n",
       "      <td>1</td>\n",
       "      <td>[alice, its, my, birthday, tomorrow, and, all,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                              tweet\n",
       "0            1  [alice, hey, baby, ,, you, wanna, pick, me, up...\n",
       "1            0  [alive, in, south, africa, (, audio, cd, get, ...\n",
       "2            0  [alice, i, actually, am, he, said, lutons, too...\n",
       "3            1  [alice, alice, these, glasses, are, very, nice...\n",
       "4            0            [alice, please, folback, this, fanbase]\n",
       "...        ...                                                ...\n",
       "79995        1  [alice, alice, of, course, !, i, follow, you, ...\n",
       "79996        0  [alice, -, he, wont, eat, or, drink, and, when...\n",
       "79997        1  [alice, no, prob, ., good, luck, !, you are, s...\n",
       "79998        1  [alice, sorry, ,, earth, day, is, the, 22nd, ....\n",
       "79999        1  [alice, its, my, birthday, tomorrow, and, all,...\n",
       "\n",
       "[80000 rows x 2 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Z0KSm0TKh5p",
    "outputId": "ee908687-aade-479e-c059-dcf5fa080288"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['val', 'train', 'train', ..., 'test', 'train', 'train'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = rng.choice(\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    size=len(train_data),\n",
    "    p=[.8, .1, .1]\n",
    ")\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "1h0aitnpEhVM"
   },
   "outputs": [],
   "source": [
    "bert_x_data = train_data[split == \"train\"]\n",
    "bert_labels = train_labels[split == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oktiMN3Nx0i",
    "outputId": "1b52e413-4268-45a7-de23-a749f6108989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='GeForce GTX 1650', major=7, minor=5, total_memory=4096MB, multi_processor_count=16)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "C15qcgvL1vd2"
   },
   "outputs": [],
   "source": [
    "bert_transformer = BertTransformer(bert_tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "F3EhqS2lNgsJ"
   },
   "outputs": [],
   "source": [
    "classifier = svm.LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "KaOdzcK1SHBS"
   },
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", bert_transformer),\n",
    "        (\"classifier\", classifier),\n",
    "    ], verbose=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1ZiubJrSJCI",
    "outputId": "e1844adf-0bc0-4cce-de70-603e2fb45701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 2) Processing vectorizer, total=10.6min\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total= 6.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 BertTransformer(bert_model=None, bert_tokenizer=None,\n",
       "                                 embedding_func=<function BertTransformer.__init__.<locals>.<lambda> at 0x000001DC532C65E8>,\n",
       "                                 max_length=60, truncate=True)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=1.0, class_weight='balanced', dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=100000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(bert_x_data, bert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "8wrvxP-FfC3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7364615865084322"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data[split == \"train\"], train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198399799974997"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_data[split == \"val\"], train_labels[split == \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = bert_transformer.transform(train_data[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = bert_transformer.transform(bert_x_data[:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=100000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_embeddings, train_labels[split == \"train\"][:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739275"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(train_embeddings, train_labels[split == \"train\"][:40000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8176395939086294"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_embeddings, train_labels[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_regr = LogisticRegression(solver=\"lbfgs\", max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr.fit(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8185279187817259"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr.score(test_embeddings, train_labels[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7880, 768])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr.predict(test_embeddings[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(train_labels[split == \"test\"], log_regr.predict(test_embeddings), labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1]), array([1, 1, 1]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[split == \"test\"][:3], log_regr.predict(test_embeddings[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3111,  854],\n",
       "       [ 576, 3339]], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolormesh(conf_mat, cmap=\"RdYlGn\")\n",
    "plt.xticks([0.5, 1.5], labels=[\"Neg\", \"Pos\"])\n",
    "plt.yticks([0.5, 1.5], labels=[\"Neg\", \"Pos\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Gold\")\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(i+.5, j+.5, str(conf_mat[j, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "gED-HlJ5MY3O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782608695652174"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(test_embeddings, train_labels[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_perceptron = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10, 2), max_iter=100000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 2), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=100000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_perceptron.fit(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444683739875463"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_perceptron.score(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237309644670051"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_perceptron.score(test_embeddings, train_labels[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(loss='squared_hinge', max_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='squared_hinge', max_iter=100000,\n",
       "                            n_iter_no_change=5, n_jobs=None, random_state=None,\n",
       "                            shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.fit(train_embeddings, train_labels[split == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110406091370559"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.score(test_embeddings, train_labels[split == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'objective':'binary:hinge', 'n_estimators':50 }\n",
    "\n",
    "clf = xgb.XGBModel(**param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mphe:0.20698\tvalidation_1-mphe:0.20842\n",
      "[1]\tvalidation_0-mphe:0.15656\tvalidation_1-mphe:0.15890\n",
      "[2]\tvalidation_0-mphe:0.14245\tvalidation_1-mphe:0.14571\n",
      "[3]\tvalidation_0-mphe:0.12972\tvalidation_1-mphe:0.13289\n",
      "[4]\tvalidation_0-mphe:0.12189\tvalidation_1-mphe:0.12642\n",
      "[5]\tvalidation_0-mphe:0.11554\tvalidation_1-mphe:0.11948\n",
      "[6]\tvalidation_0-mphe:0.11018\tvalidation_1-mphe:0.11433\n",
      "[7]\tvalidation_0-mphe:0.10552\tvalidation_1-mphe:0.11112\n",
      "[8]\tvalidation_0-mphe:0.10198\tvalidation_1-mphe:0.10734\n",
      "[9]\tvalidation_0-mphe:0.09835\tvalidation_1-mphe:0.10476\n",
      "[10]\tvalidation_0-mphe:0.09514\tvalidation_1-mphe:0.10140\n",
      "[11]\tvalidation_0-mphe:0.09207\tvalidation_1-mphe:0.10019\n",
      "[12]\tvalidation_0-mphe:0.08943\tvalidation_1-mphe:0.09809\n",
      "[13]\tvalidation_0-mphe:0.08721\tvalidation_1-mphe:0.09756\n",
      "[14]\tvalidation_0-mphe:0.08511\tvalidation_1-mphe:0.09682\n",
      "[15]\tvalidation_0-mphe:0.08266\tvalidation_1-mphe:0.09530\n",
      "[16]\tvalidation_0-mphe:0.08076\tvalidation_1-mphe:0.09367\n",
      "[17]\tvalidation_0-mphe:0.07887\tvalidation_1-mphe:0.09299\n",
      "[18]\tvalidation_0-mphe:0.07702\tvalidation_1-mphe:0.09167\n",
      "[19]\tvalidation_0-mphe:0.07554\tvalidation_1-mphe:0.09083\n",
      "[20]\tvalidation_0-mphe:0.07414\tvalidation_1-mphe:0.09062\n",
      "[21]\tvalidation_0-mphe:0.07267\tvalidation_1-mphe:0.09015\n",
      "[22]\tvalidation_0-mphe:0.07132\tvalidation_1-mphe:0.08952\n",
      "[23]\tvalidation_0-mphe:0.07028\tvalidation_1-mphe:0.08989\n",
      "[24]\tvalidation_0-mphe:0.06891\tvalidation_1-mphe:0.08952\n",
      "[25]\tvalidation_0-mphe:0.06782\tvalidation_1-mphe:0.08910\n",
      "[26]\tvalidation_0-mphe:0.06654\tvalidation_1-mphe:0.08836\n",
      "[27]\tvalidation_0-mphe:0.06546\tvalidation_1-mphe:0.08894\n",
      "[28]\tvalidation_0-mphe:0.06440\tvalidation_1-mphe:0.08799\n",
      "[29]\tvalidation_0-mphe:0.06359\tvalidation_1-mphe:0.08784\n",
      "[30]\tvalidation_0-mphe:0.06246\tvalidation_1-mphe:0.08715\n",
      "[31]\tvalidation_0-mphe:0.06184\tvalidation_1-mphe:0.08757\n",
      "[32]\tvalidation_0-mphe:0.06140\tvalidation_1-mphe:0.08710\n",
      "[33]\tvalidation_0-mphe:0.06075\tvalidation_1-mphe:0.08610\n",
      "[34]\tvalidation_0-mphe:0.06007\tvalidation_1-mphe:0.08610\n",
      "[35]\tvalidation_0-mphe:0.05930\tvalidation_1-mphe:0.08621\n",
      "[36]\tvalidation_0-mphe:0.05870\tvalidation_1-mphe:0.08547\n",
      "[37]\tvalidation_0-mphe:0.05751\tvalidation_1-mphe:0.08547\n",
      "[38]\tvalidation_0-mphe:0.05659\tvalidation_1-mphe:0.08521\n",
      "[39]\tvalidation_0-mphe:0.05607\tvalidation_1-mphe:0.08489\n",
      "[40]\tvalidation_0-mphe:0.05547\tvalidation_1-mphe:0.08458\n",
      "[41]\tvalidation_0-mphe:0.05514\tvalidation_1-mphe:0.08447\n",
      "[42]\tvalidation_0-mphe:0.05503\tvalidation_1-mphe:0.08437\n",
      "[43]\tvalidation_0-mphe:0.05431\tvalidation_1-mphe:0.08416\n",
      "[44]\tvalidation_0-mphe:0.05360\tvalidation_1-mphe:0.08437\n",
      "[45]\tvalidation_0-mphe:0.05306\tvalidation_1-mphe:0.08416\n",
      "[46]\tvalidation_0-mphe:0.05277\tvalidation_1-mphe:0.08410\n",
      "[47]\tvalidation_0-mphe:0.05252\tvalidation_1-mphe:0.08410\n",
      "[48]\tvalidation_0-mphe:0.05190\tvalidation_1-mphe:0.08400\n",
      "[49]\tvalidation_0-mphe:0.05135\tvalidation_1-mphe:0.08379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBModel(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "         colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "         importance_type='gain', interaction_constraints='',\n",
       "         learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "         min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "         n_estimators=50, n_jobs=0, num_parallel_tree=1,\n",
       "         objective='binary:hinge', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "         scale_pos_weight=None, subsample=1, tree_method='exact',\n",
       "         validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_embeddings.numpy(), train_labels[split == \"train\"], eval_set=[\n",
    "    (train_embeddings.numpy(), train_labels[split == \"train\"]),\n",
    "    (test_embeddings.numpy(), train_labels[split == \"test\"])\n",
    "],\n",
    "        eval_metric='mphe',\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977157360406092"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.predict(test_embeddings.numpy()) == train_labels[split == \"test\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by this: https://discuss.pytorch.org/t/lstm-to-bi-lstm/12967/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification with bidirectional LSTM\n",
    "class biLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings_size, hidden_size, batch_size, gpu_device):\n",
    "        super(biLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gpu_device = gpu_device\n",
    "        \n",
    "        self.lstm = nn.LSTM(embeddings_size, hidden_size, bidirectional=True, batch_first=True).to(gpu_device)\n",
    "        \n",
    "        self.out_layer = nn.Linear(hidden_size * 2, 1).to(gpu_device)\n",
    "        \n",
    "        # Classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Hidden state for LSTM\n",
    "        self.hidden_state = self.initialize_hidden()\n",
    "        \n",
    "    def initialize_hidden(self):\n",
    "        return (torch.autograd.Variable(torch.randn(2, self.batch_size, self.hidden_size)).to(self.gpu_device),   \n",
    "                torch.autograd.Variable(torch.randn(2, self.batch_size, self.hidden_size)).to(self.gpu_device))\n",
    "    \n",
    "    def detach_hidden(self):\n",
    "        self.hidden_state = (self.hidden_state[0].detach(), self.hidden_state[1].detach())\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        input_data = embeddings\n",
    "        \n",
    "#         print(\"input_data:\", input_data.is_cuda)\n",
    "#         print(\"hidden_state:\", self.hidden_state[0].is_cuda, self.hidden_state[1].is_cuda)\n",
    "        \n",
    "        lstm_output, self.hidden_state = self.lstm(input_data, self.hidden_state)\n",
    "#         print(lstm_output.shape)\n",
    "        \n",
    "        # Class decision\n",
    "        lstm_output = lstm_output[:,-1,:]\n",
    "        tags_probs = self.out_layer(lstm_output)\n",
    "        decision = self.sigmoid(tags_probs)\n",
    "        decision = decision.squeeze()\n",
    "        \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_bert = biLSTM(768, 50, batch_size=100, gpu_device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_embeddings(max_length=512):\n",
    "    def _equalize(x):\n",
    "        content = x[0]\n",
    "        long_embds = torch.zeros([content.size(0), max_length, content.size(2)])\n",
    "        long_embds[:, (max_length - content.size(1)):, :] = content\n",
    "        return long_embds\n",
    "    return _equalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sophisticated_bert = BertTransformer(bert_tokenizer, bert_model, embedding_func=equalize_embeddings(256), max_length=256, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 256, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sophisticated_embs = sophisticated_bert.transform(bert_x_data[:100])\n",
    "sophisticated_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64063,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(sophisticated_embs.squeeze(), torch.from_numpy(bert_labels[:30000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4212, 0.4394, 0.4370, 0.4397, 0.4276], device='cuda:0',\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_testset = sophisticated_embs[:5,...].squeeze().to(gpu)\n",
    "after_bert(small_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_batches(data, labels, batch_size=5):\n",
    "    for i in range(data.shape[0] // batch_size):\n",
    "        yield (data[i*batch_size:(i+1)*batch_size], labels[i*batch_size:(i+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr=0.05\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(after_bert.parameters(), lr=lr)\n",
    "\n",
    "logs_step = 100\n",
    "training_ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(after_bert.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1dc814be9c8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Loss: 0.699\n",
      "Epoch: 0 \t Loss: 0.691\n",
      "Epoch: 1 \t Loss: 0.699\n",
      "Epoch: 1 \t Loss: 0.691\n",
      "Epoch: 2 \t Loss: 0.699\n",
      "Epoch: 2 \t Loss: 0.691\n",
      "Epoch: 3 \t Loss: 0.699\n",
      "Epoch: 3 \t Loss: 0.691\n",
      "Epoch: 4 \t Loss: 0.699\n",
      "Epoch: 4 \t Loss: 0.691\n"
     ]
    }
   ],
   "source": [
    "after_bert.train()\n",
    "for epch in range(epochs):\n",
    "    for inputs, labels in get_tweet_batches(train_data[:20000], train_labels[:20000], batch_size=100):\n",
    "        training_ctr += 1\n",
    "        \n",
    "        embeddings = sophisticated_bert.transform(inputs)\n",
    "        embeddings = embeddings.squeeze()\n",
    "        labels = torch.from_numpy(labels)\n",
    "        embeddings, labels = embeddings.to(gpu), labels.to(gpu)\n",
    "        \n",
    "        after_bert.detach_hidden()\n",
    "        after_bert.zero_grad()\n",
    "        output = after_bert(embeddings)\n",
    "        loss = criterion(output, labels.float())\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(after_bert.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if training_ctr % logs_step == 0:\n",
    "            print(\"Epoch: %d \\t Loss: %.3f\" % (epch, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 0, 50), got (2, 30, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-a3b613ee68c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafter_bert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msophisticated_embs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1005\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-820d65a9aaab>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, embeddings)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#         print(\"hidden_state:\", self.hidden_state[0].is_cuda, self.hidden_state[1].is_cuda)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mlstm_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m#         print(lstm_output.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[1;32m--> 523\u001b[1;33m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[0;32m    524\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[0;32m    525\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 0, 50), got (2, 30, 50)"
     ]
    }
   ],
   "source": [
    "criterion(after_bert(sophisticated_embs.squeeze()[1000:1005,...].to(gpu)).cpu(), torch.from_numpy(bert_labels[1000:1005]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4159)"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.tensor([.5, .5, 0, .5, 0]).float(), torch.from_numpy(bert_labels[5:10]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_labels[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(emb_model, classifier_model):\n",
    "    unk_ids = []\n",
    "    unk_data = []\n",
    "    with open(\"twitter-datasets/twitter-datasets/test_data.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            comma_pos = line.find(\",\")\n",
    "            unk_ids.append(line[:comma_pos])\n",
    "            unk_data.append(line[comma_pos+1:])\n",
    "            \n",
    "    # Sanity check\n",
    "    assert len(unk_data) == 10000\n",
    "    \n",
    "    print(\"Embedding model: \" + str(type(emb_model)))\n",
    "    print(\"Calculating embeddings...\")\n",
    "    unk_embs = emb_model.transform(unk_data)\n",
    "    \n",
    "    print(\"Classifier model: \" + str(type(classifier_model)))\n",
    "    print(\"Predicting labels...\")\n",
    "    pred_labels = classifier_model.predict(unk_embs)\n",
    "    \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model: <class '__main__.BertTransformer'>\n",
      "Calculating embeddings...\n",
      "Classifier model: <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>\n",
      "Predicting labels...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_submission(bert_transformer, ml_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"men's montana boot in brown / ap green color : tan , size : 9 , width : m ( medium rm288233 - tan - 9 - m color : tan , size ... <url>\\n\""
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'tung',\n",
       " '##us',\n",
       " '##ka',\n",
       " 'mystery',\n",
       " '(',\n",
       " 'astronomers',\n",
       " \"'\",\n",
       " 'universe',\n",
       " ')',\n",
       " '(',\n",
       " 'hardcover',\n",
       " 'the',\n",
       " 'purpose',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'is',\n",
       " 'a',\n",
       " 'dual',\n",
       " 'one',\n",
       " ':',\n",
       " 'to',\n",
       " 'detail',\n",
       " 'the',\n",
       " 'n',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '<',\n",
       " 'ur',\n",
       " '##l',\n",
       " '>']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize(\"the tunguska mystery ( astronomers ' universe ) ( hardcover the purpose of the book is a dual one : to detail the n ... <url>\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CUDA_BERT-Tweets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f0b42426d3413a82961fe268ea9784": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dfaac1d07aae40cfa8dc1eaf4d05f4bb",
       "IPY_MODEL_727b19a4811447afb5e0186b5fc53957"
      ],
      "layout": "IPY_MODEL_3c9ae8f1d48444b181b2649010162d02"
     }
    },
    "1acd8910b26b42e68a89ef73f8280c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b0d40bc6e3449a5adc6bb4abeafcf2c",
       "IPY_MODEL_f46329a657d4437681d54c5dc244867b"
      ],
      "layout": "IPY_MODEL_ef4026c04d0d49f1aedf42fa97ef0dc6"
     }
    },
    "330cb9a48e7e4e2e90b6630e902494e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36a42715763d4686a65ca65020cbab18": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c9ae8f1d48444b181b2649010162d02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bf48da7a56b44918760c102f61ba13c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65fca3e9d79348afbf88c4e4d01d173c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "727b19a4811447afb5e0186b5fc53957": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a42715763d4686a65ca65020cbab18",
      "placeholder": "",
      "style": "IPY_MODEL_5bf48da7a56b44918760c102f61ba13c",
      "value": " 268M/268M [00:04&lt;00:00, 61.8MB/s]"
     }
    },
    "801d15e2514c482a8b2b5b7afd451896": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8b0d40bc6e3449a5adc6bb4abeafcf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f02d8d332daa46449a6d556f7eebd2e7",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd40c0fad38c44558b8bf14399cf5ce9",
      "value": 442
     }
    },
    "dfaac1d07aae40cfa8dc1eaf4d05f4bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65fca3e9d79348afbf88c4e4d01d173c",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_801d15e2514c482a8b2b5b7afd451896",
      "value": 267967963
     }
    },
    "e2fa89d6534d4baea5de49db4fc3f9fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef4026c04d0d49f1aedf42fa97ef0dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f02d8d332daa46449a6d556f7eebd2e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f46329a657d4437681d54c5dc244867b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2fa89d6534d4baea5de49db4fc3f9fd",
      "placeholder": "",
      "style": "IPY_MODEL_330cb9a48e7e4e2e90b6630e902494e3",
      "value": " 442/442 [00:20&lt;00:00, 21.8B/s]"
     }
    },
    "fd40c0fad38c44558b8bf14399cf5ce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
