{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_unsupervised('stage2data/train_all_full_u.txt', model='cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"stage2data/fasttext_cbow_train_full_u.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"stage2data/fasttext_cbow_train_full_u.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = model.get_input_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "np.save('stage2data/cbow_train_all_full_u.npy', input_matrix, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive tweets\n",
    "pos_tweets = []\n",
    "with open('stage2data/train_pos_full_u.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        pos_tweets.append(model.get_sentence_vector(line[:-1]))\n",
    "        \n",
    "# Load negative tweets\n",
    "neg_tweets = []\n",
    "with open('stage2data/train_neg_full_u.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        neg_tweets.append(model.get_sentence_vector(line[:-1]))\n",
    "        \n",
    "pos_tweets = np.array(pos_tweets)\n",
    "neg_tweets = np.array(neg_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('stage2data/cbow_train_pos_full_u.npy', pos_tweets, allow_pickle=True, fix_imports=True)\n",
    "np.save('stage2data/cbow_train_neg_full_u.npy', neg_tweets, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test tweets\n",
    "test_tweets = []\n",
    "with open('twitter-datasets/test_data.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        test_tweets.append(model.get_sentence_vector(line[:-1]))\n",
    "test_tweets = np.array(test_tweets)\n",
    "np.save('stage2data/cbow_test.npy', test_tweets, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"models/fasttext_cbow_train.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load positive tweets\n",
    "pos_tweets = []\n",
    "with open('twitter-datasets/train_pos_full_u.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        pos_tweets.append(model.get_sentence_vector(line[:-1]))\n",
    "        \n",
    "# Load negative tweets\n",
    "neg_tweets = []\n",
    "with open('twitter-datasets/train_neg_full_u.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        neg_tweets.append(model.get_sentence_vector(line[:-1]))\n",
    "        \n",
    "pos_tweets = np.array(pos_tweets)\n",
    "neg_tweets = np.array(neg_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = np.concatenate((pos_tweets, neg_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones(len(pos_tweets)), np.zeros(len(neg_tweets))))\n",
    "\n",
    "random_idxs = np.random.permutation(len(y))\n",
    "\n",
    "all_tweets = all_tweets[random_idxs]\n",
    "\n",
    "y = y[random_idxs]\n",
    "\n",
    "N_train = int(0.8*len(y))\n",
    "\n",
    "train, val = all_tweets[:N_train], all_tweets[N_train:]\n",
    "y_train, y_val = y[:N_train], y[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 78.42% / validation set: 78.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0, tol=1e-9, loss = 'squared_hinge', dual = True, C = 0.03)\n",
    "clf.fit(train, y_train)\n",
    "train_acc = (clf.predict(train) == y_train).mean()\n",
    "val_acc = (clf.predict(val) == y_val).mean()\n",
    "print('Training set accuracy: {:.2f}% / validation set: {:.2f}%'.format(100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
