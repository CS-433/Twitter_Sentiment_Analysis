{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import helpers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "\n",
    "full = True\n",
    "\n",
    "if full: \n",
    "    pos_filename = 'twitter-datasets/train_pos_full_u.txt'\n",
    "    neg_filename = 'twitter-datasets/train_neg_full_u.txt'\n",
    "else: \n",
    "    pos_filename = 'twitter-datasets/train_pos_u.txt'\n",
    "    neg_filename = 'twitter-datasets/train_neg_u.txt'\n",
    "\n",
    "\n",
    "pos_tweets = helpers.txt_to_list(pos_filename)\n",
    "neg_tweets = helpers.txt_to_list(neg_filename)\n",
    "\n",
    "# Create a labeled dataset \n",
    "all_tweets, y = helpers.merge_shuffle_label(pos_tweets, neg_tweets)\n",
    "\n",
    "# Split into train and validation sets\n",
    "training_fraction = 0.8\n",
    "train, val, y_train, y_val = helpers.split_dataset(training_fraction, all_tweets, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "def tk(sent):\n",
    "    tokens = p.tokenize(sent).split()\n",
    "    return tokens\n",
    "\n",
    "def tk2(sent):\n",
    "    tokens = p.tokenize(sent).split()\n",
    "    return pre.process_sentence(tokens, pre.preproc_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training vectorization \n",
    "### tfidf_vectorizer=TfidfVectorizer(use_idf=True, ngram_range = (1,2), tokenizer = TweetTokenizer().tokenize) \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, ngram_range = (1,2), tokenizer = tk)\n",
    "X_train = tfidf_vectorizer.fit_transform(train)\n",
    "X_val = tfidf_vectorizer.transform(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a few classifiers on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 86.29% / validation set: 84.91%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0, tol=1e-9, loss = 'squared_hinge', dual = True, C = 0.03)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 strongest bigrams to indicate positive sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>6.451487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( (</th>\n",
       "      <td>5.496134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( &gt;</th>\n",
       "      <td>3.664865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't wait</th>\n",
       "      <td>3.245022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; &gt;</th>\n",
       "      <td>2.967170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>2.870058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>2.619271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>2.522988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>2.412821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant wait</th>\n",
       "      <td>2.403861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no problem</th>\n",
       "      <td>2.283380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>2.250662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glad</th>\n",
       "      <td>2.234971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2.154967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>2.142214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>2.113739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haha</th>\n",
       "      <td>2.048416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i like</th>\n",
       "      <td>2.029302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yay</th>\n",
       "      <td>2.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>2.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( &lt;user&gt;</th>\n",
       "      <td>1.987620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>1.966555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$NUMBER$/20</th>\n",
       "      <td>1.947638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss me</th>\n",
       "      <td>1.934823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hehe</th>\n",
       "      <td>1.910665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proud</th>\n",
       "      <td>1.874792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome</th>\n",
       "      <td>1.873536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not bad</th>\n",
       "      <td>1.870573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1.801177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>1.789069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>1.756178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexy</th>\n",
       "      <td>1.748930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excited</th>\n",
       "      <td>1.712042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no need</th>\n",
       "      <td>1.690680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smiling</th>\n",
       "      <td>1.679250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>1.662358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't need</th>\n",
       "      <td>1.650058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congrats</th>\n",
       "      <td>1.645350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>1.627547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not too</th>\n",
       "      <td>1.622467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that's why</th>\n",
       "      <td>1.598746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodnight</th>\n",
       "      <td>1.594716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>1.568911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>1.558773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>! (</th>\n",
       "      <td>1.551146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>1.531848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.529219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>1.518675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blessed</th>\n",
       "      <td>1.467609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me luck</th>\n",
       "      <td>1.462390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitches</th>\n",
       "      <td>1.455386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodmorning</th>\n",
       "      <td>1.448398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>1.445057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thankyou</th>\n",
       "      <td>1.392836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thx</th>\n",
       "      <td>1.371325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why not</th>\n",
       "      <td>1.367355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goood</th>\n",
       "      <td>1.365538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty</th>\n",
       "      <td>1.363828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>1.358444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>1.336720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no school</th>\n",
       "      <td>1.335083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got my</th>\n",
       "      <td>1.329293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <td>1.328499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no worries</th>\n",
       "      <td>1.314794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i mean</th>\n",
       "      <td>1.308070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; _</th>\n",
       "      <td>1.307113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s /</th>\n",
       "      <td>1.290037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lets</th>\n",
       "      <td>1.289644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td>1.288625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let's</th>\n",
       "      <td>1.287866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>1.277841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>1.277246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>1.269962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>1.263454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on &lt;url&gt;</th>\n",
       "      <td>1.242634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha</th>\n",
       "      <td>1.234117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1.233236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loving</th>\n",
       "      <td>1.231467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesting</th>\n",
       "      <td>1.220299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>1.208610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mmm</th>\n",
       "      <td>1.203886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( x</th>\n",
       "      <td>1.203854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoke</th>\n",
       "      <td>1.188537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thats why</th>\n",
       "      <td>1.187742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feels good</th>\n",
       "      <td>1.187696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>1.185348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't miss</th>\n",
       "      <td>1.177681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worries</th>\n",
       "      <td>1.170479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love when</th>\n",
       "      <td>1.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aha</th>\n",
       "      <td>1.160863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>1.159132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made my</th>\n",
       "      <td>1.158443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ready</th>\n",
       "      <td>1.155519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>1.155428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td>1.149796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>1.147029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love my</th>\n",
       "      <td>1.146858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happier</th>\n",
       "      <td>1.134551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannot wait</th>\n",
       "      <td>1.133174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>least i</th>\n",
       "      <td>1.132090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coefficient\n",
       ")               6.451487\n",
       "( (             5.496134\n",
       "( >             3.664865\n",
       "can't wait      3.245022\n",
       "> >             2.967170\n",
       "thanks          2.870058\n",
       "good            2.619271\n",
       "smile           2.522988\n",
       "happy           2.412821\n",
       "cant wait       2.403861\n",
       "no problem      2.283380\n",
       "thank           2.250662\n",
       "glad            2.234971\n",
       "love            2.154967\n",
       "<user>          2.142214\n",
       "awesome         2.113739\n",
       "haha            2.048416\n",
       "i like          2.029302\n",
       "yay             2.020784\n",
       "finally         2.004700\n",
       "( <user>        1.987620\n",
       "cute            1.966555\n",
       "$NUMBER$/20     1.947638\n",
       "miss me         1.934823\n",
       "hehe            1.910665\n",
       "proud           1.874792\n",
       "welcome         1.873536\n",
       "not bad         1.870573\n",
       "you             1.801177\n",
       "great           1.789069\n",
       "amazing         1.756178\n",
       "sexy            1.748930\n",
       "excited         1.712042\n",
       "no need         1.690680\n",
       "smiling         1.679250\n",
       "nice            1.662358\n",
       "don't need      1.650058\n",
       "congrats        1.645350\n",
       "sweet           1.627547\n",
       "not too         1.622467\n",
       "that's why      1.598746\n",
       "goodnight       1.594716\n",
       "hey             1.568911\n",
       "cool            1.558773\n",
       "! (             1.551146\n",
       "lol             1.531848\n",
       "beautiful       1.529219\n",
       "best            1.518675\n",
       "blessed         1.467609\n",
       "me luck         1.462390\n",
       "bitches         1.455386\n",
       "goodmorning     1.448398\n",
       "your            1.445057\n",
       "thankyou        1.392836\n",
       "thx             1.371325\n",
       "why not         1.367355\n",
       "goood           1.365538\n",
       "pretty          1.363828\n",
       "wonderful       1.358444\n",
       "better          1.336720\n",
       "no school       1.335083\n",
       "got my          1.329293\n",
       "lovely          1.328499\n",
       "no worries      1.314794\n",
       "i mean          1.308070\n",
       "> _             1.307113\n",
       "s /             1.290037\n",
       "lets            1.289644\n",
       "worry           1.288625\n",
       "let's           1.287866\n",
       "sure            1.277841\n",
       "hello           1.277246\n",
       "enjoy           1.269962\n",
       "hi              1.263454\n",
       "on <url>        1.242634\n",
       "ha              1.234117\n",
       "!               1.233236\n",
       "loving          1.231467\n",
       "interesting     1.220299\n",
       "fun             1.208610\n",
       "mmm             1.203886\n",
       "( x             1.203854\n",
       "smoke           1.188537\n",
       "thats why       1.187742\n",
       "feels good      1.187696\n",
       "follow          1.185348\n",
       "don't miss      1.177681\n",
       "worries         1.170479\n",
       "love when       1.165100\n",
       "aha             1.160863\n",
       "funny           1.159132\n",
       "made my         1.158443\n",
       "ready           1.155519\n",
       "ya              1.155428\n",
       "worth           1.149796\n",
       "mind            1.147029\n",
       "love my         1.146858\n",
       "happier         1.134551\n",
       "cannot wait     1.133174\n",
       "least i         1.132090"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.coef_.flatten(), index=tfidf_vectorizer.get_feature_names(), columns=[\"coefficient\"]) \n",
    "n_ = 100\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('{:d} strongest bigrams to indicate positive sentiment'.format(n_))\n",
    "df.sort_values(by=[\"coefficient\"],ascending=False).head(n_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 strongest bigrams to indicate negative sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-14.028547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>... &lt;url&gt;</th>\n",
       "      <td>-10.217622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>-5.647014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss</th>\n",
       "      <td>-4.303458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>-3.767273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>) )</th>\n",
       "      <td>-3.612997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$SMILEY$ )</th>\n",
       "      <td>-3.561889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>-3.451833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crying</th>\n",
       "      <td>-3.242551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sucks</th>\n",
       "      <td>-3.199294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't</th>\n",
       "      <td>-3.134876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>-3.133930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>-2.997770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(8</th>\n",
       "      <td>-2.895640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurts</th>\n",
       "      <td>-2.884669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>-2.873177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutted</th>\n",
       "      <td>-2.869945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sick</th>\n",
       "      <td>-2.840783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nooo</th>\n",
       "      <td>-2.767596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>-2.764543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorry</th>\n",
       "      <td>-2.756985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>-2.751097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>-2.745639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>-2.720193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn't</th>\n",
       "      <td>-2.677838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadly</th>\n",
       "      <td>-2.632190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rip</th>\n",
       "      <td>-2.572104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressing</th>\n",
       "      <td>-2.564664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( $NUMBER$</th>\n",
       "      <td>-2.554695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lost</th>\n",
       "      <td>-2.543491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horrible</th>\n",
       "      <td>-2.542733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-2.538403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broke</th>\n",
       "      <td>-2.530747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>-2.511082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upset</th>\n",
       "      <td>-2.461631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigh</th>\n",
       "      <td>-2.439849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruined</th>\n",
       "      <td>-2.375482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fml</th>\n",
       "      <td>-2.367110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>-2.351264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfortunately</th>\n",
       "      <td>-2.351016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressed</th>\n",
       "      <td>-2.317781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wahhh</th>\n",
       "      <td>-2.316751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not good</th>\n",
       "      <td>-2.285013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lonely</th>\n",
       "      <td>-2.272376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wah</th>\n",
       "      <td>-2.261123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headache</th>\n",
       "      <td>-2.252269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tears</th>\n",
       "      <td>-2.242097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurt</th>\n",
       "      <td>-2.211547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>-2.180170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cried</th>\n",
       "      <td>-2.177350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant</th>\n",
       "      <td>-2.127619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omg</th>\n",
       "      <td>-2.112355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointed</th>\n",
       "      <td>-2.110245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isn't</th>\n",
       "      <td>-2.085036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scared</th>\n",
       "      <td>-2.079352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>-2.050332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>-2.024732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>-2.024236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haven't</th>\n",
       "      <td>-2.015406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didnt</th>\n",
       "      <td>-2.013247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>) &gt;</th>\n",
       "      <td>-2.002659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won't</th>\n",
       "      <td>-1.997266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waaah</th>\n",
       "      <td>-1.941583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anymore</th>\n",
       "      <td>-1.940906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotional</th>\n",
       "      <td>-1.935341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaving</th>\n",
       "      <td>-1.932011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtf</th>\n",
       "      <td>-1.894512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love you</th>\n",
       "      <td>-1.881065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worse</th>\n",
       "      <td>-1.873897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperback</th>\n",
       "      <td>-1.845287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>-1.841644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired</th>\n",
       "      <td>-1.833145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna miss</th>\n",
       "      <td>-1.822801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurting</th>\n",
       "      <td>-1.810260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broken</th>\n",
       "      <td>-1.787481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not looking</th>\n",
       "      <td>-1.785496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>-1.784862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not happy</th>\n",
       "      <td>-1.768161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terrible</th>\n",
       "      <td>-1.759012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ughhh</th>\n",
       "      <td>-1.743377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where's</th>\n",
       "      <td>-1.739638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scary</th>\n",
       "      <td>-1.739358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt; /</th>\n",
       "      <td>-1.734585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to wait</th>\n",
       "      <td>-1.726612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannot</th>\n",
       "      <td>-1.724175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if only</th>\n",
       "      <td>-1.723277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( paperback</th>\n",
       "      <td>-1.715993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poorly</th>\n",
       "      <td>-1.704339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead</th>\n",
       "      <td>-1.697727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>-1.688706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not cool</th>\n",
       "      <td>-1.686715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>! &gt;</th>\n",
       "      <td>-1.681711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smh</th>\n",
       "      <td>-1.677081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgot</th>\n",
       "      <td>-1.664925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sore</th>\n",
       "      <td>-1.657778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>-1.655790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wahh</th>\n",
       "      <td>-1.651292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfair</th>\n",
       "      <td>-1.634278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not nice</th>\n",
       "      <td>-1.633344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesn't</th>\n",
       "      <td>-1.615886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coefficient\n",
       "(               -14.028547\n",
       "... <url>       -10.217622\n",
       "sad              -5.647014\n",
       "miss             -4.303458\n",
       "poor             -3.767273\n",
       ") )              -3.612997\n",
       "$SMILEY$ )       -3.561889\n",
       "cry              -3.451833\n",
       "crying           -3.242551\n",
       "sucks            -3.199294\n",
       "can't            -3.134876\n",
       "missing          -3.133930\n",
       "wish             -2.997770\n",
       "(8               -2.895640\n",
       "hurts            -2.884669\n",
       "hate             -2.873177\n",
       "gutted           -2.869945\n",
       "sick             -2.840783\n",
       "nooo             -2.767596\n",
       "ugh              -2.764543\n",
       "sorry            -2.756985\n",
       "died             -2.751097\n",
       "missed           -2.745639\n",
       "why              -2.720193\n",
       "didn't           -2.677838\n",
       "sadly            -2.632190\n",
       "rip              -2.572104\n",
       "depressing       -2.564664\n",
       "( $NUMBER$       -2.554695\n",
       "lost             -2.543491\n",
       "horrible         -2.542733\n",
       "not              -2.538403\n",
       "broke            -2.530747\n",
       "no               -2.511082\n",
       "upset            -2.461631\n",
       "sigh             -2.439849\n",
       "ruined           -2.375482\n",
       "fml              -2.367110\n",
       "worst            -2.351264\n",
       "unfortunately    -2.351016\n",
       "depressed        -2.317781\n",
       "wahhh            -2.316751\n",
       "not good         -2.285013\n",
       "lonely           -2.272376\n",
       "wah              -2.261123\n",
       "headache         -2.252269\n",
       "tears            -2.242097\n",
       "hurt             -2.211547\n",
       "cold             -2.180170\n",
       "cried            -2.177350\n",
       "cant             -2.127619\n",
       "omg              -2.112355\n",
       "disappointed     -2.110245\n",
       "isn't            -2.085036\n",
       "scared           -2.079352\n",
       "awful            -2.050332\n",
       "pain             -2.024732\n",
       "shame            -2.024236\n",
       "haven't          -2.015406\n",
       "didnt            -2.013247\n",
       ") >              -2.002659\n",
       "won't            -1.997266\n",
       "waaah            -1.941583\n",
       "anymore          -1.940906\n",
       "emotional        -1.935341\n",
       "leaving          -1.932011\n",
       "wtf              -1.894512\n",
       "love you         -1.881065\n",
       "worse            -1.873897\n",
       "paperback        -1.845287\n",
       "never            -1.841644\n",
       "tired            -1.833145\n",
       "gonna miss       -1.822801\n",
       "hurting          -1.810260\n",
       "broken           -1.787481\n",
       "not looking      -1.785496\n",
       "bad              -1.784862\n",
       "not happy        -1.768161\n",
       "terrible         -1.759012\n",
       "ughhh            -1.743377\n",
       "where's          -1.739638\n",
       "scary            -1.739358\n",
       "< /              -1.734585\n",
       "to wait          -1.726612\n",
       "cannot           -1.724175\n",
       "if only          -1.723277\n",
       "( paperback      -1.715993\n",
       "poorly           -1.704339\n",
       "dead             -1.697727\n",
       "wrong            -1.688706\n",
       "not cool         -1.686715\n",
       "! >              -1.681711\n",
       "smh              -1.677081\n",
       "forgot           -1.664925\n",
       "sore             -1.657778\n",
       "alone            -1.655790\n",
       "wahh             -1.651292\n",
       "unfair           -1.634278\n",
       "not nice         -1.633344\n",
       "doesn't          -1.615886"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} strongest bigrams to indicate negative sentiment'.format(n_))\n",
    "df.sort_values(by=[\"coefficient\"],ascending=False).tail(n_).sort_values(by=[\"coefficient\"],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident correct predictions of positive tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks daylan ! )</th>\n",
       "      <td>4.600689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks jirah ! )</th>\n",
       "      <td>4.600689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks mcsnake ! )</th>\n",
       "      <td>4.600689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks ! )</th>\n",
       "      <td>3.799298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from awesomepictures.me ) &lt;url&gt;</th>\n",
       "      <td>3.691281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thank you cheegu ) )</th>\n",
       "      <td>3.595871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; follbackyaa thanks</th>\n",
       "      <td>3.556296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; awwuuh thanks</th>\n",
       "      <td>3.556296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; huhrhurhurhur thanks</th>\n",
       "      <td>3.556296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thank you . )</th>\n",
       "      <td>3.484261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 coefficient  label\n",
       "tweet                                              \n",
       "<user> thanks daylan ! )            4.600689      1\n",
       "<user> thanks jirah ! )             4.600689      1\n",
       "<user> thanks mcsnake ! )           4.600689      1\n",
       "<user> thanks ! )                   3.799298      1\n",
       "from awesomepictures.me ) <url>     3.691281      1\n",
       "<user> thank you cheegu ) )         3.595871      1\n",
       "<user> follbackyaa thanks           3.556296      1\n",
       "<user> awwuuh thanks                3.556296      1\n",
       "<user> huhrhurhurhur thanks         3.556296      1\n",
       "<user> thank you . )                3.484261      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dict(zip(['tweet', 'coefficient', 'label'], [val, clf.decision_function(X_val), y_val])))\n",
    "df.set_index('tweet', inplace = True)\n",
    "n_ = 10\n",
    "print('{:d} most confident correct predictions of positive tweets'.format(n_))\n",
    "df.query('label == 1').sort_values(by= 'coefficient', ascending = False).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident incorrect predictions of positive tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wingnthings ( (</th>\n",
       "      <td>-5.434482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; 14 ( wkwkwk okayy ( tell me by today yah tabb (</th>\n",
       "      <td>-2.863263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gheheheh &lt;user&gt; such a sad story ... but ... &lt;url&gt;</th>\n",
       "      <td>-2.692928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; miss you more (</th>\n",
       "      <td>-2.651623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justkidding no he didn't (</th>\n",
       "      <td>-2.392851</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; ughhh :/ i wish i did but i got home at 8: 30 and it was closed . i miss workk &lt; / 3 working saturday right ?</th>\n",
       "      <td>-2.386928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt &lt;user&gt; so .. for everbody that hurt , sad , mad , cry , feel bad , etc . because of me .. please forgive me : \" ( no body perfec</th>\n",
       "      <td>-2.384424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; aww really (</th>\n",
       "      <td>-2.357661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks gutted i missed glee though . not gutted i missed rachel though #stuckuphorse</th>\n",
       "      <td>-2.345663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i wanna talk to #oomf ( ( (</th>\n",
       "      <td>-2.317131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    coefficient  label\n",
       "tweet                                                                 \n",
       "wingnthings ( (                                       -5.434482      1\n",
       "<user> 14 ( wkwkwk okayy ( tell me by today yah...    -2.863263      1\n",
       "gheheheh <user> such a sad story ... but ... <url>    -2.692928      1\n",
       "<user> miss you more (                                -2.651623      1\n",
       "justkidding no he didn't (                            -2.392851      1\n",
       "<user> ughhh :/ i wish i did but i got home at ...    -2.386928      1\n",
       "rt <user> so .. for everbody that hurt , sad , ...    -2.384424      1\n",
       "<user> aww really (                                   -2.357661      1\n",
       "<user> thanks gutted i missed glee though . not...    -2.345663      1\n",
       "i wanna talk to #oomf ( ( (                           -2.317131      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident incorrect predictions of positive tweets'.format(n_))\n",
    "df.query('label == 1').sort_values(by= 'coefficient', ascending = True).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident correct predictions of negative tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wish i was at aviciii (</th>\n",
       "      <td>-4.966417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; sigghhhss ( (</th>\n",
       "      <td>-4.892636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt &lt;user&gt; nfl draft 1st rd by state : tx ( 5 tn ( 3 al ( 2 ca ( 2 fl ( 2 ok ( 2 oh ( 2 11 states with ( 1 )</th>\n",
       "      <td>-4.851107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's cold in here ( ( and i'm all alone ( ( i'm cold : ( ( ( guise i can't breathe ( i hate rummm !</th>\n",
       "      <td>-4.694607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the lastborn of elvinwood ( paperback &lt;url&gt;</th>\n",
       "      <td>-4.361577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some other countries in this low category include haiti ( 0.454 zimbabwe ( 0.376 sudan ( 0.408 sierra leone ( ... &lt;url&gt;</th>\n",
       "      <td>-4.167410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woke up early . ( 7 hours omg (</th>\n",
       "      <td>-4.033661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this movie is making me cry &lt; / 3 ( (</th>\n",
       "      <td>-4.003928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; i wish i was ( (</th>\n",
       "      <td>-3.965345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i miss them (</th>\n",
       "      <td>-3.931083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    coefficient  label\n",
       "tweet                                                                 \n",
       "wish i was at aviciii (                               -4.966417      0\n",
       "<user> sigghhhss ( (                                  -4.892636      0\n",
       "rt <user> nfl draft 1st rd by state : tx ( 5 tn...    -4.851107      0\n",
       "it's cold in here ( ( and i'm all alone ( ( i'm...    -4.694607      0\n",
       "the lastborn of elvinwood ( paperback <url>           -4.361577      0\n",
       "some other countries in this low category inclu...    -4.167410      0\n",
       "woke up early . ( 7 hours omg (                       -4.033661      0\n",
       "this movie is making me cry < / 3 ( (                 -4.003928      0\n",
       "<user> i wish i was ( (                               -3.965345      0\n",
       "i miss them (                                         -3.931083      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident correct predictions of negative tweets'.format(n_))\n",
    "df.query('label == 0').sort_values(by= 'coefficient', ascending = True).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident incorrect predictions of negative tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thank you )</th>\n",
       "      <td>3.452199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; )</th>\n",
       "      <td>3.068503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; 7abeeebty thank you</th>\n",
       "      <td>2.910433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; happy birthday to him of course )</th>\n",
       "      <td>2.319080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; twitteameee</th>\n",
       "      <td>2.288357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; i-d-i-o-t-a</th>\n",
       "      <td>2.288357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; mthatha</th>\n",
       "      <td>2.288357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; chuta</th>\n",
       "      <td>2.288357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks #miss you</th>\n",
       "      <td>2.162552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks rhyno</th>\n",
       "      <td>2.129335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          coefficient  label\n",
       "tweet                                                       \n",
       "<user> thank you )                           3.452199      0\n",
       "<user> )                                     3.068503      0\n",
       "<user> 7abeeebty thank you                   2.910433      0\n",
       "<user> happy birthday to him of course )     2.319080      0\n",
       "<user> twitteameee                           2.288357      0\n",
       "<user> i-d-i-o-t-a                           2.288357      0\n",
       "<user> mthatha                               2.288357      0\n",
       "<user> chuta                                 2.288357      0\n",
       "<user> thanks #miss you                      2.162552      0\n",
       "<user> thanks rhyno                          2.129335      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident incorrect predictions of negative tweets'.format(n_))\n",
    "df.query('label == 0').sort_values(by= 'coefficient', ascending = False).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 86.71% / validation set: 81.65%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 80.62% / validation set: 75.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 80.62% / validation set: 75.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 78.49% / validation set: 78.48%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf =  linear_model.SGDClassifier(loss = 'log', max_iter=int(1e7), tol=1e-5, verbose = False)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 96.80% / validation set: 81.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf =  linear_model.Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 397. MiB for an array with shape (52029241,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c8902cf2cb1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             )\n\u001b[1;32m--> 303\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    304\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    576\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;31m# create new with correct sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mspmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             \u001b[0mchanged_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[1;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         csr_tocsc(self.shape[0], self.shape[1],\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 397. MiB for an array with shape (52029241,) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test set\n",
    "test_tweets = []\n",
    "with open('twitter-datasets/test_data.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        sp = line.split(',')\n",
    "        index = sp[0]\n",
    "        test_tweets.append(','.join(sp[1:]))\n",
    "        \n",
    "# Compute tf-idf on full training set      \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, ngram_range = (1,2), tokenizer = TweetTokenizer().tokenize) \n",
    "X_train_final = tfidf_vectorizer.fit_transform(all_tweets)\n",
    "X_test = tfidf_vectorizer.transform(test_tweets)\n",
    "\n",
    "# Check training accuracy\n",
    "clf = LinearSVC(random_state=0, tol=1e-9, loss = 'squared_hinge', dual = True, C = 0.03)\n",
    "clf.fit(X_train_final, y)\n",
    "\n",
    "train_acc = (clf.predict(X_train_final) == y).mean()\n",
    "print('Training set accuracy: {:.2f}%'.format(100*train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save predictions\n",
    "save_filename = 'submissions/submission_tfidf.csv'\n",
    "predictions = clf.predict(X_test)\n",
    "helpers.save_pred(save_filename, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embeddings/tfidf_unique_full_train.npy', X_train_final)\n",
    "np.save('embeddings/tfidf_unique_full_labels.npy', y)\n",
    "np.save('embeddings/tfidf_unique_full_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.load('embeddings/tfidf_unique_full_train.npy', allow_pickle = True)\n",
    "y = np.load('embeddings/tfidf_unique_full_labels.npy', allow_pickle = True)\n",
    "X_test = np.load('embeddings/tfidf_unique_full_test.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
