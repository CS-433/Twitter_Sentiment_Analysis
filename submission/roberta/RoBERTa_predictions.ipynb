{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiC8CffiJHCT"
   },
   "source": [
    "# **RoBERTa** - Predictions\n",
    "This notebook loads our finetuned model and computes predictions\n",
    "\n",
    "## Model description\n",
    " 1. RoBERTa + Linear head\n",
    " 2. CrossEntropy Loss\n",
    " 3. Finetuned RoBERTa\n",
    " 5. Preprocessing pipeline _'standard'_\n",
    "\n",
    "## Notes\n",
    "GPU is **not** required (but it helps, around 2GB of dedicated memory are required to calculate predictions with a batch size of 32)\n",
    "\n",
    "## Credits\n",
    "Some ideas were taken from https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "\n",
    "## Reproducibility\n",
    "The predictions obtained with this notebook match those of Submission **#108663** on AIcrowd\n",
    "\n",
    "| Accuracy | F1 |\n",
    "|:---:|:---:|\n",
    "| 90.0% | 90.1% |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3LAcQ5NwOXR"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zyuAMjiwYmf",
    "outputId": "85394f9a-6a3c-4a7a-f0c2-8208d59f4378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 5.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 19.5MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 26.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=989b3998c964172384a4350bb26f3430472cfca43f93492d0823421e819872e0\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n",
      "Collecting wordsegment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8MB 4.7MB/s \n",
      "\u001b[?25hInstalling collected packages: wordsegment\n",
      "Successfully installed wordsegment-1.3.1\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# # Libraries that could be missing\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install transformers\n",
    "# !pip install wordsegment\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YxF7HI1W4u3v"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sDBG-UenSK48"
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-BrK3x_E1CzH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imsUgzFRwLAI",
    "outputId": "7e27fd9c-5c78-4afb-d00f-9de71a0f0b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Contains preprocessing functions\n",
    "from preprocessing_v6 import *\n",
    "# Contains all the functions related to the model\n",
    "from roberta_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Vmt0t-UkJon"
   },
   "source": [
    "## GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87t2iYsukJon",
    "outputId": "241b3653-1859-42c7-8b29-3e71dd1b2ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if possible\n",
    "if torch.cuda.is_available():\n",
    "  used_device = torch.device('cuda:0')\n",
    "  print(\"Using GPU:\", torch.cuda.get_device_properties('cuda:0'))\n",
    "else:\n",
    "  used_device = torch.device('cpu')\n",
    "  print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7OgJPTFLz-T"
   },
   "source": [
    "## Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAJTLBDS44VS",
    "outputId": "93f8e92e-8c1f-4d2a-d425-9bcd8ba22b0c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1Hfg5tryRiEn"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.add_prefix_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7VzF_gAP3sM",
    "outputId": "7e47a7eb-d47e-496b-8839-14b4149e1916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing preprocessing & tokenizer...\n",
      "Original sentence: that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\n",
      "Processed sentence: ['that', 'Ġis', 'Ġa', 'Ġvery', 'Ġbad', 'Ġsentence', 'Ġ<', 'user', '>', 'Ġ<', 'url', '>', 'Ġyou', 'Ġare', 'Ġgoing', 'Ġto', 'Ġlove', 'Ġit', '.', 'Ġlet', 'Ġme', 'Ġknow', 'Ġwhat', 'Ġyou', 'Ġthink', 'Ġ:', '-', '/']\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessing\n",
    "sample_sentence = \"that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\"\n",
    "print(\"Testing preprocessing & tokenizer...\")\n",
    "print(\"Original sentence:\", sample_sentence)\n",
    "print(\"Processed sentence:\", bert_tokenizer.tokenize(apply_preprocessing(bert_tokenizer, sample_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMkwtsSC6Csd",
    "outputId": "fc1d4543-bcb8-4646-a9d9-2ff974ca9873"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVumh2c3kJoo"
   },
   "source": [
    "## Define the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8kERT15OwLAK"
   },
   "outputs": [],
   "source": [
    "# Max number of tokens in each tweet>\n",
    "MAX_LENGTH = 200\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "# Filename of predictions\n",
    "PREDICTIONS_FILENAME = \"predictions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLAZRHfskJop"
   },
   "source": [
    "## Load fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Btf6xb-kJop",
    "outputId": "bb0402e1-4ce0-4249-a364-4f8b263f60dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-16 13:05:38--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3UvcyFBclREZ3U5ejdJT1ZqcU1ndVZGUzV0RDdJeTFIUUE_ZT1wRW9q/root/content\n",
      "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
      "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://d2pbrw.db.files.1drv.com/y4mTId-TFwJFbJrCdmNdgHvky3s_t7WCLJx3wcUulxrXyjT9_RJKVEQxIxQVR5Y99Fd90fVgWIF0mmtqwBr00q3P3wRnvPwkuvMhm05cyvFNTKJpaOiSXbLlwWcrJU06vXGyaejGjfO8WtfENUReYnkUIsjlXaNb98C8xfRGcRqoF7GYIpGVCajyt3TI1nFGznHXixq2LoVGWvZR4YPGvhUSQ/RoBERTa_preproc_std_1epch.pth [following]\n",
      "--2020-12-16 13:05:38--  https://d2pbrw.db.files.1drv.com/y4mTId-TFwJFbJrCdmNdgHvky3s_t7WCLJx3wcUulxrXyjT9_RJKVEQxIxQVR5Y99Fd90fVgWIF0mmtqwBr00q3P3wRnvPwkuvMhm05cyvFNTKJpaOiSXbLlwWcrJU06vXGyaejGjfO8WtfENUReYnkUIsjlXaNb98C8xfRGcRqoF7GYIpGVCajyt3TI1nFGznHXixq2LoVGWvZR4YPGvhUSQ/RoBERTa_preproc_std_1epch.pth\n",
      "Resolving d2pbrw.db.files.1drv.com (d2pbrw.db.files.1drv.com)... 13.107.42.12\n",
      "Connecting to d2pbrw.db.files.1drv.com (d2pbrw.db.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 498679525 (476M) [application/zip]\n",
      "Saving to: ‘RoBERTa_finetuned_std.pth’\n",
      "\n",
      "RoBERTa_finetuned_s 100%[===================>] 475.58M  29.7MB/s    in 17s     \n",
      "\n",
      "2020-12-16 13:05:56 (27.9 MB/s) - ‘RoBERTa_finetuned_std.pth’ saved [498679525/498679525]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download our \"finetuned\" model\n",
    "!wget -O RoBERTa_finetuned_std.pth https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3UvcyFBclREZ3U5ejdJT1ZqcU1ndVZGUzV0RDdJeTFIUUE_ZT1wRW9q/root/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9AdKzr1kJop",
    "outputId": "733d1161-ef9c-45c5-836d-79966460e200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = load_model(\"RoBERTa_finetuned_std\", bert_model, used_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL3RoQEWkJop"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBPSdR2e7Dba",
    "outputId": "afaa4e51-d592-4c8a-f834-821cb3135f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-16 13:11:48--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content\n",
      "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
      "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://43loag.db.files.1drv.com/y4mXjx_iztEzPDr2_yEraDIdBKOZgu7urAv8l930TMSuHIzGvuuFoS5EfKK4GgVbyI14jS0zrrS931mmVdpBJy7ijfAC-JdaNmzUA6UaAGlRPgFHOMpuv1AGSx8mXlfcvy3wvWFXD_SU74GTlcsVczeKhgAYKm143iI_FhQ3xJt4LHHaGElsHNgoLfjIrFmv55BCkb-Wn44B_ej_zp_5Xu4yg/test_data.txt [following]\n",
      "--2020-12-16 13:11:49--  https://43loag.db.files.1drv.com/y4mXjx_iztEzPDr2_yEraDIdBKOZgu7urAv8l930TMSuHIzGvuuFoS5EfKK4GgVbyI14jS0zrrS931mmVdpBJy7ijfAC-JdaNmzUA6UaAGlRPgFHOMpuv1AGSx8mXlfcvy3wvWFXD_SU74GTlcsVczeKhgAYKm143iI_FhQ3xJt4LHHaGElsHNgoLfjIrFmv55BCkb-Wn44B_ej_zp_5Xu4yg/test_data.txt\n",
      "Resolving 43loag.db.files.1drv.com (43loag.db.files.1drv.com)... 13.107.42.12\n",
      "Connecting to 43loag.db.files.1drv.com (43loag.db.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 817297 (798K) [text/plain]\n",
      "Saving to: ‘test_data.txt’\n",
      "\n",
      "test_data.txt       100%[===================>] 798.14K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2020-12-16 13:11:50 (10.2 MB/s) - ‘test_data.txt’ saved [817297/817297]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download test_data.txt\n",
    "!wget -O test_data.txt https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMwOMNVK9Szb",
    "outputId": "bb19674a-db2f-4205-eebc-90d62e433656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Content: [1, 2] ['sea doo pro sea scooter ( sports with the portable sea-doo seascootersave air , stay longer in the water and ... <url>\\n', \"<user> shucks well i work all week so now i can't come cheer you on ! oh and put those batteries in your calculator ! ! !\\n\"]\n",
      "Create dataloader...\n",
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "submission_idxs, submission_labels, _ = prepare_submission(reloaded_model, bert_tokenizer, used_device, batch_size=BATCH_SIZE, max_len=MAX_LENGTH, test_filename=\"test_data.txt\")\n",
    "submission_idxs, submission_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRGSxy_B_5Uj"
   },
   "outputs": [],
   "source": [
    "write_submission(PREDICTIONS_FILENAME, submission_idxs, submission_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfN9GVGRnbVS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RoBERTa_predictions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
