{
 "cells": [
  {
   "source": [
    "# Model\n",
    "This notebook loads our finetuned model and computes predictions\n",
    "\n",
    "## Description\n",
    " 1. RoBERTa + Dropout + Linear\n",
    " 2. CrossEntropy Loss\n",
    " 3. Finetuning RoBERTa\n",
    " 3. Adam with Weight decay optimizer (https://arxiv.org/abs/1711.05101)\n",
    " 4. Cosine schedule\n",
    " 5. Preprocessing ('standard' + 'extended')\n",
    "\n",
    "## Notes\n",
    "GPU required\n",
    "\n",
    "## Credits\n",
    "Some ideas were taken from https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "AiC8CffiJHCT"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3LAcQ5NwOXR"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zyuAMjiwYmf",
    "outputId": "4f438035-fb97-4bda-b743-dba4e4a9777d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install wordsegment\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YxF7HI1W4u3v"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDBG-UenSK48"
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BrK3x_E1CzH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imsUgzFRwLAI",
    "outputId": "7eaa3491-0c18-46e5-e406-ed30aab153b2"
   },
   "outputs": [],
   "source": [
    "from preprocessing_v6 import *"
   ]
  },
  {
   "source": [
    "## GPU check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"A CUDA-enabled GPU is required to execute this notebook (in a reasonable time)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU detected:\", torch.cuda.get_device_properties('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7OgJPTFLz-T"
   },
   "source": [
    "## Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAJTLBDS44VS",
    "outputId": "ee62d12c-b8df-4125-a6ad-a7cb3f0e1016",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Hfg5tryRiEn"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.add_prefix_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYV2iQDwvtxt"
   },
   "outputs": [],
   "source": [
    "def apply_preprocessing(tweet):\n",
    "    return \" \".join(process_sentence(tweet.split(\" \"), extended_pipeline(bert_tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7VzF_gAP3sM",
    "outputId": "a8937d05-4463-41c7-b74d-e22198aad23c"
   },
   "outputs": [],
   "source": [
    "# Test preprocessing\n",
    "sample_sentence = \"that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\"\n",
    "print(\"Testing preprocessing & tokenizer...\")\n",
    "print(\"Original sentence:\", sample_sentence)\n",
    "print(\"Processed sentence:\", bert_tokenizer.tokenize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMkwtsSC6Csd",
    "outputId": "9f557d94-8de3-4392-a6f9-3b7041cea004"
   },
   "outputs": [],
   "source": [
    "bert_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2XefgNT1JVp"
   },
   "outputs": [],
   "source": [
    "class RobertaSimple(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_model\n",
    "    ):\n",
    "        super(RobertaSimple, self).__init__()\n",
    "        self.model = bert_model\n",
    "\n",
    "    def forward(self, input_ids, input_attention, labels):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=input_attention, labels=labels)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXPyUFiIwLAJ"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, chunks, labels, tokenizer, max_len):\n",
    "        self.chunks = chunks\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.chunks.shape[0]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.chunks[item]\n",
    "        labels = self.labels[item]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            apply_preprocessing(sentence),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmJeHXSIL3sU"
   },
   "outputs": [],
   "source": [
    "# Initialize random state (for reproducibility)\n",
    "rng = RandomState(124)"
   ]
  },
  {
   "source": [
    "## Define parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kERT15OwLAK"
   },
   "outputs": [],
   "source": [
    "# Max number of tokens in each tweet\n",
    "MAX_LENGTH = 200\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "# Number of training epochs\n",
    "EPOCHS = 2"
   ]
  },
  {
   "source": [
    "## Load fine-tuned model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename, bert_model, device):\n",
    "    model = RobertaSimple(bert_model)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(filename + \".pth\"))\n",
    "    model.eval()\n",
    "    print(\"Model loaded\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Download model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = load_model(\"RoBERTa_preproc_std_0epch\", bert_model, gpu)"
   ]
  },
  {
   "source": [
    "## Predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!wget -O test_data.txt https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content"
   ],
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBPSdR2e7Dba",
    "outputId": "b02db34e-085f-4a7c-ef53-cb7e0f898832"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fOi2cxc793I"
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    idxs = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            idx = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                input_attention=attention_mask,\n",
    "                labels=torch.zeros(idx.shape[0], dtype=torch.long).to(device),\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            idxs.append(idx.cpu())\n",
    "            predictions.append(preds.cpu())\n",
    "\n",
    "    return np.concatenate(idxs), np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4MB7sZQ6b7j"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(model, device, filename=\"test_data.txt\"):\n",
    "    print(\"Loading file...\")\n",
    "    unk_ids = []\n",
    "    unk_data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            comma_pos = line.find(\",\")\n",
    "            unk_ids.append(int(line[:comma_pos]))\n",
    "            unk_data.append(line[comma_pos+1:])\n",
    "            \n",
    "    # Sanity check\n",
    "    assert len(unk_data) == 10000\n",
    "\n",
    "    print(\"Content:\", unk_ids[:2], unk_data[:2])\n",
    "    \n",
    "    print(\"Create dataloader...\")\n",
    "    dataset = SentimentDataset(\n",
    "        np.array(unk_data), \n",
    "        np.array(unk_ids), \n",
    "        tokenizer=bert_tokenizer, \n",
    "        max_len=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    d_loader = get_loader(dataset)\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    return predict(model, d_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMwOMNVK9Szb",
    "outputId": "6d90b2cf-7936-421f-814f-cfd259566a5f"
   },
   "outputs": [],
   "source": [
    "submission_idxs, submission_labels = prepare_submission(reloaded_model, gpu)\n",
    "submission_idxs, submission_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ldN_1zY-3Ez"
   },
   "outputs": [],
   "source": [
    "def write_submission(filename, idxs, labels):\n",
    "  # Convert to -1, 11\n",
    "  labels = (labels * 2 - 1).astype(int)\n",
    "  idxs = idxs.astype(int)\n",
    "  submission_content = np.concatenate([idxs[..., np.newaxis], labels[..., np.newaxis]], axis=1).astype(int)\n",
    "  print(submission_content)\n",
    "  np.savetxt(filename, submission_content, fmt='%d', delimiter=',', header=\"Id,Prediction\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRGSxy_B_5Uj",
    "outputId": "704cee16-99bf-49cf-a8d9-500eef60d4a0"
   },
   "outputs": [],
   "source": [
    "# Filename of predictions\n",
    "PREDICTIONS_FILENAME = \"sub_reloaded.csv\"\n",
    "write_submission(PREDICTIONS_FILENAME, submission_idxs, submission_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RoBERTa_preproc_Tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}