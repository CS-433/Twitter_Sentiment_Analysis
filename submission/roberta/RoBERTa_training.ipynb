{
 "cells": [
  {
   "source": [
    "# Model\n",
    "\n",
    "## Description\n",
    " 1. RoBERTa + Dropout + Linear\n",
    " 2. CrossEntropy Loss\n",
    " 3. Finetuning RoBERTa\n",
    " 3. Adam with Weight decay optimizer (https://arxiv.org/abs/1711.05101)\n",
    " 4. Cosine schedule\n",
    " 5. Preprocessing ('standard' + 'extended')\n",
    "\n",
    "## Notes\n",
    "GPU required\n",
    "\n",
    "## Credits\n",
    "Some ideas were taken from https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "AiC8CffiJHCT"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3LAcQ5NwOXR"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zyuAMjiwYmf",
    "outputId": "4f438035-fb97-4bda-b743-dba4e4a9777d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install wordsegment\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YxF7HI1W4u3v"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDBG-UenSK48"
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BrK3x_E1CzH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imsUgzFRwLAI",
    "outputId": "7eaa3491-0c18-46e5-e406-ed30aab153b2"
   },
   "outputs": [],
   "source": [
    "from preprocessing_v6 import *"
   ]
  },
  {
   "source": [
    "## GPU check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"A CUDA-enabled GPU is required to execute this notebook (in a reasonable time)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU detected:\", torch.cuda.get_device_properties('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7OgJPTFLz-T"
   },
   "source": [
    "## Load components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAJTLBDS44VS",
    "outputId": "ee62d12c-b8df-4125-a6ad-a7cb3f0e1016",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Hfg5tryRiEn"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.add_prefix_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYV2iQDwvtxt"
   },
   "outputs": [],
   "source": [
    "def apply_preprocessing(tweet):\n",
    "    return \" \".join(process_sentence(tweet.split(\" \"), extended_pipeline(bert_tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7VzF_gAP3sM",
    "outputId": "a8937d05-4463-41c7-b74d-e22198aad23c"
   },
   "outputs": [],
   "source": [
    "# Test preprocessing\n",
    "sample_sentence = \"that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\"\n",
    "print(\"Testing preprocessing & tokenizer...\")\n",
    "print(\"Original sentence:\", sample_sentence)\n",
    "print(\"Processed sentence:\", bert_tokenizer.tokenize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMkwtsSC6Csd",
    "outputId": "9f557d94-8de3-4392-a6f9-3b7041cea004"
   },
   "outputs": [],
   "source": [
    "bert_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2XefgNT1JVp"
   },
   "outputs": [],
   "source": [
    "class RobertaSimple(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_model\n",
    "    ):\n",
    "        super(RobertaSimple, self).__init__()\n",
    "        self.model = bert_model\n",
    "\n",
    "    def forward(self, input_ids, input_attention, labels):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=input_attention, labels=labels)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXPyUFiIwLAJ"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, chunks, labels, tokenizer, max_len):\n",
    "        self.chunks = chunks\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.chunks.shape[0]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.chunks[item]\n",
    "        labels = self.labels[item]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            apply_preprocessing(sentence),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmJeHXSIL3sU"
   },
   "outputs": [],
   "source": [
    "# Initialize random state (for reproducibility)\n",
    "rng = RandomState(124)"
   ]
  },
  {
   "source": [
    "## Define parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kERT15OwLAK"
   },
   "outputs": [],
   "source": [
    "# Max number of tokens in each tweet\n",
    "MAX_LENGTH = 200\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "# Number of training epochs\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlMYxKEh36ic"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Du8OPNMP7Px_"
   },
   "outputs": [],
   "source": [
    "# Download negative small\n",
    "# !wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQyeURtYWFXMzZoMnVEeGc_ZT1IMnhQ/root/content -O neg_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M3JP-E17SpL"
   },
   "outputs": [],
   "source": [
    "# Download positive small\n",
    "# !wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQxYUNPOENKdTBrX19hY2c_ZT1WNW5Y/root/content -O pos_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBdqRehYk95m",
    "outputId": "bd36faaf-cd28-4a2c-c960-135e7a13285e"
   },
   "outputs": [],
   "source": [
    "# Download negative full\n",
    "!wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQ0eDZMdDI5WXBlVXYyZGc_ZT1ZZDJn/root/content -O neg_full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V42-UlNGVwaL",
    "outputId": "5b62fad0-cac6-4be3-d32f-e827319c6aaa"
   },
   "outputs": [],
   "source": [
    "# Download positive full\n",
    "!wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQzcTc3QmNPbUdIWHQ3TXc_ZT01ejdG/root/content -O pos_full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6v4fUY04WjI"
   },
   "outputs": [],
   "source": [
    "neg_train = []\n",
    "with open(\"neg_full.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        neg_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4rsAd4MD0j8"
   },
   "outputs": [],
   "source": [
    "pos_train = []\n",
    "with open(\"pos_full.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        pos_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9Ik30qoDTZB",
    "outputId": "5fc058ce-2f79-4f77-b1eb-d2c23234e64d"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset loaded. Size: \\t negative %d \\t positive %d\" % (len(neg_train), len(pos_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5xR1ZKpwLAK"
   },
   "source": [
    "### Re-establish balance between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CbPADOlwLAK"
   },
   "outputs": [],
   "source": [
    "if len(neg_train) < len(pos_train):\n",
    "  pos_train = neg_train[:len(neg_train)-len(pos_train)]\n",
    "elif len(neg_train) > len(pos_train):\n",
    "  neg_train = neg_train[:len(pos_train)-len(neg_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brgye2sqwLAK"
   },
   "outputs": [],
   "source": [
    "assert len(neg_train) == len(pos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkTtCLBmxStp"
   },
   "source": [
    "### Trim and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W2gXvm0xeHh"
   },
   "outputs": [],
   "source": [
    "samples_num_by_cat = 1_120_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euNoeET9e07T"
   },
   "outputs": [],
   "source": [
    "neg_train = neg_train[:samples_num_by_cat]\n",
    "pos_train = pos_train[:samples_num_by_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmmBj-UpHL8s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([[0] * len(neg_train), [1] * len(pos_train)])\n",
    "train_data = np.concatenate([neg_train, pos_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZlpxdtqK_tu",
    "outputId": "ede8eb90-2273-4d92-f9e1-c1389b9ef1f7"
   },
   "outputs": [],
   "source": [
    "shuffling = np.arange(0, train_data.shape[0])\n",
    "len(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmBQ5G89L8-G"
   },
   "outputs": [],
   "source": [
    "rng.shuffle(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmgYUmgbMAFZ"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[shuffling]\n",
    "train_data = train_data[shuffling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZWehjwewLAK",
    "outputId": "b26d5bb9-597c-427c-9e1c-cd291f6e4dc0"
   },
   "outputs": [],
   "source": [
    "split = rng.choice(\n",
    "    [\"train\", \"val\"],\n",
    "    size=len(train_data),\n",
    "    p=[.9, .1]\n",
    ")\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1h0aitnpEhVM"
   },
   "outputs": [],
   "source": [
    "bert_x_data = train_data[split == \"train\"]\n",
    "bert_labels = train_labels[split == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKkzosniwLAK"
   },
   "outputs": [],
   "source": [
    "def get_loader(dataset):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JndebrhSwLAK"
   },
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(\n",
    "    train_data[split == \"train\"], \n",
    "    train_labels[split == \"train\"], \n",
    "    tokenizer=bert_tokenizer, \n",
    "    max_len=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Se0EREarwLAK"
   },
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqQwAI0mwLAK",
    "outputId": "f67abf48-243c-45b0-fbaf-941781b432b9"
   },
   "outputs": [],
   "source": [
    "print(\"Random sample:\")\n",
    "train_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAL6TM_A1o7x"
   },
   "outputs": [],
   "source": [
    "val_dataset = SentimentDataset(\n",
    "    train_data[split == \"val\"], \n",
    "    train_labels[split == \"val\"], \n",
    "    tokenizer=bert_tokenizer, \n",
    "    max_len=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKXvjfB61ym-"
   },
   "outputs": [],
   "source": [
    "val_loader = get_loader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPni6FSWwLAK",
    "outputId": "6f7812ec-6aca-4ccd-9341-1b3b3518d8d4"
   },
   "outputs": [],
   "source": [
    "print(\"Training set size: %d \\t Validation set size: %d\" % (len(train_dataset), len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd-06Pm13-gQ"
   },
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C15qcgvL1vd2"
   },
   "outputs": [],
   "source": [
    "bert_classification = RobertaSimple(bert_model)\n",
    "bert_classification = bert_classification.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "3u4ufnwdwLAL",
    "outputId": "c05c7b8d-02b0-4fb8-d00d-71f4d08ea516"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(bert_classification.parameters(), lr=2e-5, correct_bias=False)\n",
    "tot_steps = EPOCHS * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ODGBQJOwLAL"
   },
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=tot_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yvejQO2wLAL"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                input_attention=attention_mask,\n",
    "                labels=targets\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            num_preds += targets.shape[0]\n",
    "            losses.append(loss.item())\n",
    "    return correct_predictions.double() / float(num_preds), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iSeuiZ2wLAL"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"labels\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      input_attention=attention_mask,\n",
    "      labels=targets\n",
    "    )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    loss = outputs.loss\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5J49r7oAEGi"
   },
   "outputs": [],
   "source": [
    "def save_model(filename, model):\n",
    "    torch.save(model.state_dict(), filename + \".pth\")\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpzpUYTdzn_z",
    "outputId": "fc990409-30dc-46aa-a955-dbcb85538470"
   },
   "outputs": [],
   "source": [
    "# Train the model and store it\n",
    "for epch in range(EPOCHS):\n",
    "  print(\"EPOCH: \", epch)\n",
    "  print(\"\\t Train: \", train_epoch(bert_classification, train_loader, optimizer, gpu, scheduler, len(train_dataset)))\n",
    "  print(\"\\t Validation: \", eval_model(bert_classification, val_loader, gpu))\n",
    "  save_model(\"RoBERTa_preproc_\" + str(epch) + \"epch\", bert_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDkgWaGL1R95",
    "outputId": "7e662867-e32c-48fe-9fbb-e6c5c1e0b8eb"
   },
   "outputs": [],
   "source": [
    "eval_model(bert_classification, all_neg_loader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VkrNc2F67MF"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBPSdR2e7Dba",
    "outputId": "b02db34e-085f-4a7c-ef53-cb7e0f898832"
   },
   "outputs": [],
   "source": [
    "!wget -O test_data.txt https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fOi2cxc793I"
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    idxs = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            idx = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                input_attention=attention_mask,\n",
    "                labels=torch.zeros(idx.shape[0], dtype=torch.long).to(device),\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            idxs.append(idx.cpu())\n",
    "            predictions.append(preds.cpu())\n",
    "\n",
    "    return np.concatenate(idxs), np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4MB7sZQ6b7j"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(model, device, filename=\"test_data.txt\"):\n",
    "    print(\"Loading file...\")\n",
    "    unk_ids = []\n",
    "    unk_data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            comma_pos = line.find(\",\")\n",
    "            unk_ids.append(int(line[:comma_pos]))\n",
    "            unk_data.append(line[comma_pos+1:])\n",
    "            \n",
    "    # Sanity check\n",
    "    assert len(unk_data) == 10000\n",
    "\n",
    "    print(\"Content:\", unk_ids[:2], unk_data[:2])\n",
    "    \n",
    "    print(\"Create dataloader...\")\n",
    "    dataset = SentimentDataset(\n",
    "        np.array(unk_data), \n",
    "        np.array(unk_ids), \n",
    "        tokenizer=bert_tokenizer, \n",
    "        max_len=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    d_loader = get_loader(dataset)\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    return predict(model, d_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMwOMNVK9Szb",
    "outputId": "6d90b2cf-7936-421f-814f-cfd259566a5f"
   },
   "outputs": [],
   "source": [
    "submission_idxs, submission_labels = prepare_submission(bert_classification, gpu)\n",
    "submission_idxs, submission_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ldN_1zY-3Ez"
   },
   "outputs": [],
   "source": [
    "def write_submission(filename, idxs, labels):\n",
    "  # Convert to -1, 11\n",
    "  labels = (labels * 2 - 1).astype(int)\n",
    "  idxs = idxs.astype(int)\n",
    "  submission_content = np.concatenate([idxs[..., np.newaxis], labels[..., np.newaxis]], axis=1).astype(int)\n",
    "  print(submission_content)\n",
    "  np.savetxt(filename, submission_content, fmt='%d', delimiter=',', header=\"Id,Prediction\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRGSxy_B_5Uj",
    "outputId": "704cee16-99bf-49cf-a8d9-500eef60d4a0"
   },
   "outputs": [],
   "source": [
    "# Filename of predictions\n",
    "PREDICTIONS_FILENAME = \"sub_preproc.csv\"\n",
    "write_submission(PREDICTIONS_FILENAME, submission_idxs, submission_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSB09r6zE20i"
   },
   "outputs": [],
   "source": [
    "# Not yet tested\n",
    "def load_model(filename, bert_model, device):\n",
    "    model = RobertaSimple(bert_model)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(filename + \".pth\"))\n",
    "    model.eval()\n",
    "    print(\"Model loaded\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "tuX7jBHWErS6",
    "outputId": "1fe6d961-ad65-4bd9-de67-bedcd9919c32"
   },
   "outputs": [],
   "source": [
    "# save_model(\"sub2\", bert_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlxKidneT3od"
   },
   "outputs": [],
   "source": [
    "reloaded_model = load_model(\"RoBERTa_preproc_std_0epch\", bert_model, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyeF0Fh2Ud8A",
    "outputId": "00c8fc8d-2c48-4201-e940-7a2b08af601f"
   },
   "outputs": [],
   "source": [
    "_, reloaded_preds = prepare_submission(reloaded_model, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFVsREvjUrsy",
    "outputId": "ced77670-f159-42bb-928b-d60f8881761e"
   },
   "outputs": [],
   "source": [
    "reloaded_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhCZKb9xYBbz",
    "outputId": "06114f29-8203-43e7-d463-846264230074"
   },
   "outputs": [],
   "source": [
    "write_submission(\"RoBERTa_std_epch0.csv\", np.arange(1, 10001, 1), reloaded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lOgnhLwsrUh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RoBERTa_preproc_Tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}