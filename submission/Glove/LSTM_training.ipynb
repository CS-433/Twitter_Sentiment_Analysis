{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4881,
     "status": "ok",
     "timestamp": 1608200069558,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "WQHZ443ABHA_",
    "outputId": "f3078a59-5873-43dc-d40c-01d3baa44dc7"
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Bidirectional\n",
    "from keras.layers import Flatten , Dropout\n",
    "from keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n",
    "import preprocessing as pre\n",
    "from keras.callbacks import EarlyStopping\n",
    "import LSTM_models as mod\n",
    "import os\n",
    "import wget\n",
    "root = 'data/'\n",
    "os.makedirs(root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40qCpNwOhkxA"
   },
   "source": [
    "#  import data after removing duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 32070,
     "status": "ok",
     "timestamp": 1608200096767,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "loyX2Vy-XNfx"
   },
   "outputs": [],
   "source": [
    "# Download negative full\n",
    "neg_url = 'https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQ0eDZMdDI5WXBlVXYyZGc_ZT1ZZDJn/root/content'\n",
    "neg_filename = root + 'train_neg_full_u.txt'\n",
    "wget.download(neg_url, neg_filename)\n",
    "neg_tweets = mod.txt_to_list(neg_filename)\n",
    "\n",
    "# Download positive full\n",
    "pos_url = 'https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQzcTc3QmNPbUdIWHQ3TXc_ZT01ejdG/root/content'\n",
    "pos_filename = root + 'train_pos_full_u.txt'\n",
    "wget.download(pos_url, pos_filename)\n",
    "pos_tweets = mod.txt_to_list(pos_filename)\n",
    "\n",
    "# Merge positive and negative tweets\n",
    "all_tweets=np.concatenate([pos_tweets,neg_tweets])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RhGjBNJXNfy"
   },
   "source": [
    "# Import pre-trained Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 370541,
     "status": "ok",
     "timestamp": 1608200467351,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "FWv8GxB0XNfy",
    "outputId": "7c203e80-3aec-470d-906b-2ff1d310ffa5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'data/embeddings (1).txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download embeddings\n",
    "emb_url=\"https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcU00WDhTRmwzcWpCcVhKdXc_ZT1nMjRX/root/content\"\n",
    "emb_filename= root +'embeddings.txt'\n",
    "wget.download(emb_url, emb_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAMZs5Z0hkxB"
   },
   "source": [
    "#  Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 878373,
     "status": "ok",
     "timestamp": 1608200978106,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "UgqaSDqbhkxC"
   },
   "outputs": [],
   "source": [
    "#Preprocess the tweets with the standard_pipeline in preprocessing\n",
    "processed_tweets=[pre.process_sentence(tweet.split(' '),pre.standard_pipeline) for tweet in all_tweets]\n",
    "docs=[' '.join(tweet) for tweet in processed_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQUT_wk9hkxC"
   },
   "source": [
    "#  Prepare inputs for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76397,
     "status": "ok",
     "timestamp": 1608201096347,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "stMWJIZcBSc_",
    "outputId": "5654370c-4a4b-43a2-e629-0051016c5586"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    32      1    302 ...      0      0      0]\n",
      " [     1   7687     26 ...      0      0      0]\n",
      " [     1      2   1496 ...      0      0      0]\n",
      " ...\n",
      " [ 29812      1     12 ...      0      0      0]\n",
      " [ 29812      1      5 ...      0      0      0]\n",
      " [423219    180  73400 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 40 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOf6AkE0hkxD"
   },
   "source": [
    "# Create dictionnary with Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 131193,
     "status": "ok",
     "timestamp": 1608201160488,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "u-WlP2kmhkxE"
   },
   "outputs": [],
   "source": [
    "word_emb = dict()\n",
    "with open(emb_filename) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        K=line.split()\n",
    "        word_emb[K[0]]=np.float_(K[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBWOUS5OpoYP"
   },
   "source": [
    "# Create embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1821,
     "status": "ok",
     "timestamp": 1608201162335,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "IlkuLA2JIRYi"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 200))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = word_emb.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUnRBx-ihkxF"
   },
   "source": [
    "# Create labels vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.zeros(len(all_tweets))\n",
    "labels[:len(pos_tweets)]=0\n",
    "labels[len(pos_tweets):]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMEQLHaFqWsS"
   },
   "source": [
    "# Shuffle and split the data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1258,
     "status": "ok",
     "timestamp": 1608201213572,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "NMK8Xd8TY_Sb"
   },
   "outputs": [],
   "source": [
    "random_idxs = np.random.permutation(len(labels))\n",
    "padded_docs = padded_docs[random_idxs]\n",
    "labels = labels[random_idxs]\n",
    "\n",
    "N_train = int(0.9*len(labels))\n",
    "\n",
    "X_train, X_val = padded_docs[:N_train], padded_docs[N_train:]\n",
    "y_train, y_val = labels[:N_train], labels[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7gMT2gihkxG"
   },
   "source": [
    "# Create the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1608201849515,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "P_4eym-wJTUG",
    "outputId": "fa4440b8-84c6-440b-aabc-a91be645bc6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 200)           84644000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100)               100800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 84,744,901\n",
      "Trainable params: 100,901\n",
      "Non-trainable params: 84,644,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 200, weights=[embedding_matrix],input_length=50, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Bidirectional(CuDNNLSTM(50)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzKyS4vIhkxJ"
   },
   "source": [
    "# Train the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4935437,
     "status": "ok",
     "timestamp": 1608175588467,
     "user": {
      "displayName": "Seif Ben Mustapha",
      "photoUrl": "",
      "userId": "01494195177638299220"
     },
     "user_tz": -60
    },
    "id": "z7ybfWOBhkxJ",
    "outputId": "8a70cd2b-2c30-49cd-a078-95d995bfce94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 40).\n",
      "63858/63858 [==============================] - 493s 8ms/step - loss: 0.3720 - accuracy: 0.8302\n",
      "Epoch 2/10\n",
      "63858/63858 [==============================] - 488s 8ms/step - loss: 0.3481 - accuracy: 0.8439\n",
      "Epoch 3/10\n",
      "63858/63858 [==============================] - 489s 8ms/step - loss: 0.3407 - accuracy: 0.8477\n",
      "Epoch 4/10\n",
      "63858/63858 [==============================] - 489s 8ms/step - loss: 0.3363 - accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "63858/63858 [==============================] - 489s 8ms/step - loss: 0.3329 - accuracy: 0.8519\n",
      "Epoch 6/10\n",
      "63858/63858 [==============================] - 489s 8ms/step - loss: 0.3303 - accuracy: 0.8532\n",
      "Epoch 7/10\n",
      "63858/63858 [==============================] - 488s 8ms/step - loss: 0.3282 - accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "63858/63858 [==============================] - 487s 8ms/step - loss: 0.3262 - accuracy: 0.8553\n",
      "Epoch 9/10\n",
      "63858/63858 [==============================] - 487s 8ms/step - loss: 0.3245 - accuracy: 0.8564\n",
      "Epoch 10/10\n",
      "63858/63858 [==============================] - 490s 8ms/step - loss: 0.3227 - accuracy: 0.8568\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"embedding_input:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 40).\n",
      "Accuracy: 84.676433\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', min_delta=0, patience=1)\n",
    "history = model.fit(X_train, y_train, epochs=10, verbose=1, callbacks=[es])\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
