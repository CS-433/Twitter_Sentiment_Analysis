{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "\n",
    "full = True\n",
    "\n",
    "if full: \n",
    "    pos_filename = 'twitter-datasets/train_pos_full_u.txt'\n",
    "    neg_filename = 'twitter-datasets/train_neg_full_u.txt'\n",
    "else: \n",
    "    pos_filename = 'twitter-datasets/train_pos_u.txt'\n",
    "    neg_filename = 'twitter-datasets/train_neg_u.txt'\n",
    "\n",
    "\n",
    "pos_tweets = helpers.txt_to_list(pos_filename)\n",
    "neg_tweets = helpers.txt_to_list(neg_filename)\n",
    "\n",
    "# Create a labeled dataset \n",
    "all_tweets, y = helpers.merge_shuffle_label(pos_tweets, neg_tweets)\n",
    "\n",
    "# Split into train and validation sets\n",
    "training_fraction = 0.8\n",
    "train, val, y_train, y_val = helpers.split_dataset(training_fraction, all_tweets, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816385,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<user> i'm so upset your not going this weekend have fun at stage coach\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Matteo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "from preprocessing import process_sentence, to_vec, split_hashtag, words_to_tags, remove_repeats, detect_laugh\n",
    "\n",
    "def tk(sent):\n",
    "    tokens = p.tokenize(sent).split()\n",
    "    return tokens\n",
    "\n",
    "def tk2(sent):\n",
    "    tokens = p.tokenize(sent).split()\n",
    "    return pre.process_sentence(tokens, pre.preproc_pipeline)\n",
    "\n",
    "preproc_pipeline = [to_vec(split_hashtag), \n",
    "                   to_vec(words_to_tags), \n",
    "                   to_vec(remove_repeats),\n",
    "                   to_vec(detect_laugh)]\n",
    "\n",
    "def tk3(sent):\n",
    "    tokens = TweetTokenizer().tokenize(sent)\n",
    "    return process_sentence(tokens, preproc_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training vectorization \n",
    "### tfidf_vectorizer=TfidfVectorizer(use_idf=True, ngram_range = (1,2), tokenizer = TweetTokenizer().tokenize) \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True, ngram_range = (1,2), tokenizer = tk3)\n",
    "X_train = tfidf_vectorizer.fit_transform(train)\n",
    "X_val = tfidf_vectorizer.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816385, 4557026)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 58, 31, ..., 26, 34, 39], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of valid entries in each row\n",
    "non_zero_by_row = np.diff(X_train.tocsr().indptr)\n",
    "non_zero_by_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_by_row.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alice', \"alice i'm\", 'at', 'at stage', 'coach', 'fun', 'fun at',\n",
       "       'going', 'going this', 'have', 'have fun', \"i'm\", \"i'm so\", 'not',\n",
       "       'not going', 'so', 'so upset', 'stage', 'stage coach', 'this',\n",
       "       'this wekend', 'upset', 'upset your', 'wekend', 'wekend have',\n",
       "       'your', 'your not'], dtype='<U163')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tfidf_vectorizer.get_feature_names())[[ 617107,  633072,  798423,  807566, 1233576, 1825515, 1825657,\n",
    "        1913157, 1914351, 2015694, 2018390, 2160663, 2164629, 2931135,\n",
    "        2933905, 3662285, 3668963, 3736351, 3736443, 4003422, 4013937,\n",
    "        4219311, 4219643, 4338174, 4338656, 4523796, 4530335]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " array([ 541248,  546111,  671766,  674115, 1565513, 2145806, 2146282,\n",
       "        2971121, 2993009, 3083452, 3083476, 3462241, 3462338, 3922041,\n",
       "        3935086, 3950911, 4251646, 4252913], dtype=int64))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(tfidf_vectorizer.transform([\"i am very sad about the outcome of the election\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['about', 'about the', 'am', 'am very', 'election', 'i', 'i am',\n",
       "       'of', 'of the', 'outcome', 'outcome of', 'sad', 'sad about', 'the',\n",
       "       'the election', 'the outcome', 'very', 'very sad'], dtype='<U163')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tfidf_vectorizer.get_feature_names())[[ 541248,  546111,  671766,  674115, 1565513, 2145806, 2146282,\n",
    "        2971121, 2993009, 3083452, 3083476, 3462241, 3462338, 3922041,\n",
    "        3935086, 3950911, 4251646, 4252913]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a few classifiers on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 86.57% / validation set: 85.11%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=0, tol=1e-9, loss = 'squared_hinge', dual = True, C = 0.03)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 strongest bigrams to indicate positive sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>6.530061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( (</th>\n",
       "      <td>5.821362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( &gt;</th>\n",
       "      <td>3.755154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't wait</th>\n",
       "      <td>3.350554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; &gt;</th>\n",
       "      <td>3.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>2.823874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no problem</th>\n",
       "      <td>2.531068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant wait</th>\n",
       "      <td>2.525956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smile</th>\n",
       "      <td>2.511491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hapy</th>\n",
       "      <td>2.375419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>2.349030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yay</th>\n",
       "      <td>2.300511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice</th>\n",
       "      <td>2.184160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ways to make me hapy</th>\n",
       "      <td>2.182150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>2.163449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glad</th>\n",
       "      <td>2.152993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2.118308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( alice</th>\n",
       "      <td>2.088218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[LAUGH]</th>\n",
       "      <td>2.053515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finaly</th>\n",
       "      <td>2.033660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you get major points if</th>\n",
       "      <td>2.009070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i like</th>\n",
       "      <td>1.991925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/20</th>\n",
       "      <td>1.971242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>1.968786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proud</th>\n",
       "      <td>1.968273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cute</th>\n",
       "      <td>1.897972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smart nokia lumi a</th>\n",
       "      <td>1.894181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hehe</th>\n",
       "      <td>1.878426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mis me</th>\n",
       "      <td>1.859806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welcome</th>\n",
       "      <td>1.829779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not bad</th>\n",
       "      <td>1.821075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>1.802715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excited</th>\n",
       "      <td>1.799918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>1.761094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1.759083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexy</th>\n",
       "      <td>1.753438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thoughts during schol</th>\n",
       "      <td>1.753208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>1.732171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no ned</th>\n",
       "      <td>1.702464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godnight</th>\n",
       "      <td>1.681944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>1.672477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>! (</th>\n",
       "      <td>1.667271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smiling</th>\n",
       "      <td>1.665976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congrats</th>\n",
       "      <td>1.631079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blesed</th>\n",
       "      <td>1.622777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don't ned</th>\n",
       "      <td>1.620906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swet</th>\n",
       "      <td>1.593652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that's why</th>\n",
       "      <td>1.578775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not to</th>\n",
       "      <td>1.540061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godmorning</th>\n",
       "      <td>1.527000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitches</th>\n",
       "      <td>1.507362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.503865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col</th>\n",
       "      <td>1.489371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me luck</th>\n",
       "      <td>1.479337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>1.443327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; _</th>\n",
       "      <td>1.441576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i find that atractive</th>\n",
       "      <td>1.431909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <td>1.421066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helo</th>\n",
       "      <td>1.400049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no schol</th>\n",
       "      <td>1.400037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>1.392691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no wories</th>\n",
       "      <td>1.390793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thankyou</th>\n",
       "      <td>1.378668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prety</th>\n",
       "      <td>1.367208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[LAUGH] (</th>\n",
       "      <td>1.348625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beter</th>\n",
       "      <td>1.345307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thx</th>\n",
       "      <td>1.343671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i mean</th>\n",
       "      <td>1.339242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>1.334177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lets</th>\n",
       "      <td>1.330644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>let's</th>\n",
       "      <td>1.323774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>1.322424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1.321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>1.306114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hary poter chat up lines</th>\n",
       "      <td>1.304003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aye</th>\n",
       "      <td>1.303962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why not</th>\n",
       "      <td>1.300814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>1.293430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got my</th>\n",
       "      <td>1.287238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wory</th>\n",
       "      <td>1.283923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha</th>\n",
       "      <td>1.281911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fels god</th>\n",
       "      <td>1.280439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1.271151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>1.270505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wining</th>\n",
       "      <td>1.263134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aha</th>\n",
       "      <td>1.259559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made my</th>\n",
       "      <td>1.252513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>1.251925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant say no</th>\n",
       "      <td>1.233559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s /</th>\n",
       "      <td>1.231332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loving</th>\n",
       "      <td>1.226648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>om f</th>\n",
       "      <td>1.214046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love when</th>\n",
       "      <td>1.208300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>np</th>\n",
       "      <td>1.203563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>1.195019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on [UNK]</th>\n",
       "      <td>1.188728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canot wait</th>\n",
       "      <td>1.169908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folow</th>\n",
       "      <td>1.165274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just saying</th>\n",
       "      <td>1.162821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wories</th>\n",
       "      <td>1.162481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          coefficient\n",
       ")                            6.530061\n",
       "( (                          5.821362\n",
       "( >                          3.755154\n",
       "can't wait                   3.350554\n",
       "> >                          3.019469\n",
       "thanks                       2.823874\n",
       "no problem                   2.531068\n",
       "cant wait                    2.525956\n",
       "smile                        2.511491\n",
       "hapy                         2.375419\n",
       "god                          2.349030\n",
       "yay                          2.300511\n",
       "alice                        2.184160\n",
       "ways to make me hapy         2.182150\n",
       "awesome                      2.163449\n",
       "glad                         2.152993\n",
       "love                         2.118308\n",
       "( alice                      2.088218\n",
       "[LAUGH]                      2.053515\n",
       "finaly                       2.033660\n",
       "you get major points if      2.009070\n",
       "i like                       1.991925\n",
       "4/20                         1.971242\n",
       "thank                        1.968786\n",
       "proud                        1.968273\n",
       "cute                         1.897972\n",
       "smart nokia lumi a           1.894181\n",
       "hehe                         1.878426\n",
       "mis me                       1.859806\n",
       "welcome                      1.829779\n",
       "not bad                      1.821075\n",
       "amazing                      1.802715\n",
       "excited                      1.799918\n",
       "nice                         1.761094\n",
       "you                          1.759083\n",
       "sexy                         1.753438\n",
       "thoughts during schol        1.753208\n",
       "great                        1.732171\n",
       "no ned                       1.702464\n",
       "godnight                     1.681944\n",
       "hey                          1.672477\n",
       "! (                          1.667271\n",
       "smiling                      1.665976\n",
       "congrats                     1.631079\n",
       "blesed                       1.622777\n",
       "don't ned                    1.620906\n",
       "swet                         1.593652\n",
       "that's why                   1.578775\n",
       "not to                       1.540061\n",
       "godmorning                   1.527000\n",
       "bitches                      1.507362\n",
       "beautiful                    1.503865\n",
       "col                          1.489371\n",
       "me luck                      1.479337\n",
       "best                         1.443327\n",
       "> _                          1.441576\n",
       "i find that atractive        1.431909\n",
       "lovely                       1.421066\n",
       "helo                         1.400049\n",
       "no schol                     1.400037\n",
       "your                         1.392691\n",
       "no wories                    1.390793\n",
       "thankyou                     1.378668\n",
       "prety                        1.367208\n",
       "[LAUGH] (                    1.348625\n",
       "beter                        1.345307\n",
       "thx                          1.343671\n",
       "i mean                       1.339242\n",
       "yes                          1.334177\n",
       "lets                         1.330644\n",
       "let's                        1.323774\n",
       "wonderful                    1.322424\n",
       "!                            1.321600\n",
       "enjoy                        1.306114\n",
       "hary poter chat up lines     1.304003\n",
       "aye                          1.303962\n",
       "why not                      1.300814\n",
       "hi                           1.293430\n",
       "got my                       1.287238\n",
       "wory                         1.283923\n",
       "ha                           1.281911\n",
       "fels god                     1.280439\n",
       "420                          1.271151\n",
       "fun                          1.270505\n",
       "wining                       1.263134\n",
       "aha                          1.259559\n",
       "made my                      1.252513\n",
       "sure                         1.251925\n",
       "cant say no                  1.233559\n",
       "s /                          1.231332\n",
       "loving                       1.226648\n",
       "om f                         1.214046\n",
       "love when                    1.208300\n",
       "np                           1.203563\n",
       "ya                           1.195019\n",
       "on [UNK]                     1.188728\n",
       "canot wait                   1.169908\n",
       "folow                        1.165274\n",
       "just saying                  1.162821\n",
       "wories                       1.162481"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.coef_.flatten(), index=tfidf_vectorizer.get_feature_names(), columns=[\"coefficient\"]) \n",
    "n_ = 100\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('{:d} strongest bigrams to indicate positive sentiment'.format(n_))\n",
    "df.sort_values(by=[\"coefficient\"],ascending=False).head(n_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 strongest bigrams to indicate negative sentiment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>-14.557267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>... [UNK]</th>\n",
       "      <td>-10.545662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>-5.551473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mis</th>\n",
       "      <td>-4.226630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>) )</th>\n",
       "      <td>-3.694160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wah</th>\n",
       "      <td>-3.612889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>por</th>\n",
       "      <td>-3.609854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>-3.431948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crying</th>\n",
       "      <td>-3.282803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't</th>\n",
       "      <td>-3.150341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>-3.126442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(8</th>\n",
       "      <td>-3.125049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sucks</th>\n",
       "      <td>-3.113236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mising</th>\n",
       "      <td>-3.101499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guted</th>\n",
       "      <td>-3.014564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>-3.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sick</th>\n",
       "      <td>-2.851486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>-2.811902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurts</th>\n",
       "      <td>-2.771485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sory</th>\n",
       "      <td>-2.762038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fml</th>\n",
       "      <td>-2.757736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>-2.754868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>-2.752427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>-2.719014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mised</th>\n",
       "      <td>-2.683853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadly</th>\n",
       "      <td>-2.673918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=) )</th>\n",
       "      <td>-2.666566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad twet</th>\n",
       "      <td>-2.651827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depresing</th>\n",
       "      <td>-2.645921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rip</th>\n",
       "      <td>-2.622914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn't</th>\n",
       "      <td>-2.581873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horible</th>\n",
       "      <td>-2.576490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigh</th>\n",
       "      <td>-2.569963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lost</th>\n",
       "      <td>-2.527582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-2.523757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depresed</th>\n",
       "      <td>-2.503454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upset</th>\n",
       "      <td>-2.429591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruined</th>\n",
       "      <td>-2.342006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfortunately</th>\n",
       "      <td>-2.341334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headache</th>\n",
       "      <td>-2.336036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lonely</th>\n",
       "      <td>-2.326516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broke</th>\n",
       "      <td>-2.325810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>-2.321401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disapointed</th>\n",
       "      <td>-2.294890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scared</th>\n",
       "      <td>-2.220079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cried</th>\n",
       "      <td>-2.195234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurt</th>\n",
       "      <td>-2.178361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>-2.174502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tears</th>\n",
       "      <td>-2.170308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not god</th>\n",
       "      <td>-2.119429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant</th>\n",
       "      <td>-2.119321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awful</th>\n",
       "      <td>-2.074483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omg</th>\n",
       "      <td>-2.063393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isn't</th>\n",
       "      <td>-2.049709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haven't</th>\n",
       "      <td>-2.015352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didnt</th>\n",
       "      <td>-2.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>won't</th>\n",
       "      <td>-1.991920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anymore</th>\n",
       "      <td>-1.964033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>-1.963650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>-1.935720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wtf</th>\n",
       "      <td>-1.934103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worse</th>\n",
       "      <td>-1.926320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotional</th>\n",
       "      <td>-1.912967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaving</th>\n",
       "      <td>-1.890612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not hapy</th>\n",
       "      <td>-1.883682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>) &gt;</th>\n",
       "      <td>-1.864040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired</th>\n",
       "      <td>-1.808069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terible</th>\n",
       "      <td>-1.803591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>-1.783993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not loking</th>\n",
       "      <td>-1.770999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>painful</th>\n",
       "      <td>-1.767595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broken</th>\n",
       "      <td>-1.765307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love you</th>\n",
       "      <td>-1.760731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfair</th>\n",
       "      <td>-1.755525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperback</th>\n",
       "      <td>-1.752714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gona mis</th>\n",
       "      <td>-1.749392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurting</th>\n",
       "      <td>-1.749016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not col</th>\n",
       "      <td>-1.745500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where's</th>\n",
       "      <td>-1.743768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not nice</th>\n",
       "      <td>-1.737879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fel</th>\n",
       "      <td>-1.727650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>-1.722454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smh</th>\n",
       "      <td>-1.720111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>-1.719541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt alice</th>\n",
       "      <td>-1.716151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scary</th>\n",
       "      <td>-1.700986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dying</th>\n",
       "      <td>-1.699049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ouch</th>\n",
       "      <td>-1.698815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dead</th>\n",
       "      <td>-1.698346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>-1.696221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so sad</th>\n",
       "      <td>-1.692237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canot</th>\n",
       "      <td>-1.688937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if only</th>\n",
       "      <td>-1.688286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to wait</th>\n",
       "      <td>-1.675835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>! &gt;</th>\n",
       "      <td>-1.671684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>-1.648855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>( paperback</th>\n",
       "      <td>-1.632165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sore</th>\n",
       "      <td>-1.631844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doesn't</th>\n",
       "      <td>-1.620365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not fair</th>\n",
       "      <td>-1.616124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coefficient\n",
       "(               -14.557267\n",
       "... [UNK]       -10.545662\n",
       "sad              -5.551473\n",
       "mis              -4.226630\n",
       ") )              -3.694160\n",
       "wah              -3.612889\n",
       "por              -3.609854\n",
       "cry              -3.431948\n",
       "crying           -3.282803\n",
       "can't            -3.150341\n",
       "ugh              -3.126442\n",
       "(8               -3.125049\n",
       "sucks            -3.113236\n",
       "mising           -3.101499\n",
       "guted            -3.014564\n",
       "wish             -3.003569\n",
       "sick             -2.851486\n",
       "hate             -2.811902\n",
       "hurts            -2.771485\n",
       "sory             -2.762038\n",
       "fml              -2.757736\n",
       "why              -2.754868\n",
       "no               -2.752427\n",
       "died             -2.719014\n",
       "mised            -2.683853\n",
       "sadly            -2.673918\n",
       "=) )             -2.666566\n",
       "sad twet         -2.651827\n",
       "depresing        -2.645921\n",
       "rip              -2.622914\n",
       "didn't           -2.581873\n",
       "horible          -2.576490\n",
       "sigh             -2.569963\n",
       "lost             -2.527582\n",
       "not              -2.523757\n",
       "depresed         -2.503454\n",
       "upset            -2.429591\n",
       "ruined           -2.342006\n",
       "unfortunately    -2.341334\n",
       "headache         -2.336036\n",
       "lonely           -2.326516\n",
       "broke            -2.325810\n",
       "worst            -2.321401\n",
       "disapointed      -2.294890\n",
       "scared           -2.220079\n",
       "cried            -2.195234\n",
       "hurt             -2.178361\n",
       "cold             -2.174502\n",
       "tears            -2.170308\n",
       "not god          -2.119429\n",
       "cant             -2.119321\n",
       "awful            -2.074483\n",
       "omg              -2.063393\n",
       "isn't            -2.049709\n",
       "haven't          -2.015352\n",
       "didnt            -2.000333\n",
       "won't            -1.991920\n",
       "anymore          -1.964033\n",
       "pain             -1.963650\n",
       "shame            -1.935720\n",
       "wtf              -1.934103\n",
       "worse            -1.926320\n",
       "emotional        -1.912967\n",
       "leaving          -1.890612\n",
       "not hapy         -1.883682\n",
       ") >              -1.864040\n",
       "tired            -1.808069\n",
       "terible          -1.803591\n",
       "never            -1.783993\n",
       "not loking       -1.770999\n",
       "painful          -1.767595\n",
       "broken           -1.765307\n",
       "love you         -1.760731\n",
       "unfair           -1.755525\n",
       "paperback        -1.752714\n",
       "gona mis         -1.749392\n",
       "hurting          -1.749016\n",
       "not col          -1.745500\n",
       "where's          -1.743768\n",
       "not nice         -1.737879\n",
       "fel              -1.727650\n",
       "wa               -1.722454\n",
       "smh              -1.720111\n",
       "wrong            -1.719541\n",
       "rt alice         -1.716151\n",
       "scary            -1.700986\n",
       "dying            -1.699049\n",
       "ouch             -1.698815\n",
       "dead             -1.698346\n",
       "bad              -1.696221\n",
       "so sad           -1.692237\n",
       "canot            -1.688937\n",
       "if only          -1.688286\n",
       "to wait          -1.675835\n",
       "! >              -1.671684\n",
       "alone            -1.648855\n",
       "( paperback      -1.632165\n",
       "sore             -1.631844\n",
       "doesn't          -1.620365\n",
       "not fair         -1.616124"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} strongest bigrams to indicate negative sentiment'.format(n_))\n",
    "df.sort_values(by=[\"coefficient\"],ascending=False).tail(n_).sort_values(by=[\"coefficient\"],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident correct predictions of positive tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fucklovesexmoneyonly )</th>\n",
       "      <td>6.686995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks jirah ! )</th>\n",
       "      <td>4.656479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks dianamite ! )</th>\n",
       "      <td>4.656479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; coool ! ) sure sure ! ) hahaha thanks ys )</th>\n",
       "      <td>4.050394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thank youuu ! ) you too ! )</th>\n",
       "      <td>4.007262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; owkej thanks</th>\n",
       "      <td>3.539907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; haha ) yeahh . ilove you more ) lol you are more amazing and sweet )</th>\n",
       "      <td>3.446162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; &lt;user&gt; thank you ! ) )</th>\n",
       "      <td>3.429393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks for follow me ) nice to know you )</th>\n",
       "      <td>3.408739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thank you )</th>\n",
       "      <td>3.402971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    coefficient  label\n",
       "tweet                                                                 \n",
       "fucklovesexmoneyonly )                                 6.686995      1\n",
       "<user> thanks jirah ! )                                4.656479      1\n",
       "<user> thanks dianamite ! )                            4.656479      1\n",
       "<user> coool ! ) sure sure ! ) hahaha thanks ys )      4.050394      1\n",
       "<user> thank youuu ! ) you too ! )                     4.007262      1\n",
       "<user> owkej thanks                                    3.539907      1\n",
       "<user> haha ) yeahh . ilove you more ) lol you ...     3.446162      1\n",
       "<user> <user> thank you ! ) )                          3.429393      1\n",
       "<user> thanks for follow me ) nice to know you )       3.408739      1\n",
       "<user> thank you )                                     3.402971      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dict(zip(['tweet', 'coefficient', 'label'], [val, clf.decision_function(X_val), y_val])))\n",
    "df.set_index('tweet', inplace = True)\n",
    "n_ = 10\n",
    "print('{:d} most confident correct predictions of positive tweets'.format(n_))\n",
    "df.query('label == 1').sort_values(by= 'coefficient', ascending = False).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident incorrect predictions of positive tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the weeknd-thursday (</th>\n",
       "      <td>-10.515300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ohheythere ... &lt;url&gt;</th>\n",
       "      <td>-6.544099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; i know (</th>\n",
       "      <td>-3.195289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i want to cry</th>\n",
       "      <td>-2.718442</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; ohh (</th>\n",
       "      <td>-2.692335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; miss you more (</th>\n",
       "      <td>-2.687864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; i want some (</th>\n",
       "      <td>-2.540041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its only tuesday damn ... (</th>\n",
       "      <td>-2.516003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its 5:11 ( #itsanalainerthing</th>\n",
       "      <td>-2.479460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justkidding no he didn't (</th>\n",
       "      <td>-2.463262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               coefficient  label\n",
       "tweet                                            \n",
       "the weeknd-thursday (           -10.515300      1\n",
       "ohheythere ... <url>             -6.544099      1\n",
       "<user> i know (                  -3.195289      1\n",
       "i want to cry                    -2.718442      1\n",
       "<user> ohh (                     -2.692335      1\n",
       "<user> miss you more (           -2.687864      1\n",
       "<user> i want some (             -2.540041      1\n",
       "its only tuesday damn ... (      -2.516003      1\n",
       "its 5:11 ( #itsanalainerthing    -2.479460      1\n",
       "justkidding no he didn't (       -2.463262      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident incorrect predictions of positive tweets'.format(n_))\n",
    "df.query('label == 1').sort_values(by= 'coefficient', ascending = True).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident correct predictions of negative tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>really sad i had to miss the #gsqaud game (</th>\n",
       "      <td>-4.745569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's cold in here ( ( and i'm all alone ( ( i'm cold : ( ( ( guise i can't breathe ( i hate rummm !</th>\n",
       "      <td>-4.489991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ughh i hate this (</th>\n",
       "      <td>-4.317277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i miss this (</th>\n",
       "      <td>-4.144280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt &lt;user&gt; ( ( ( sad until cannot sad fml</th>\n",
       "      <td>-4.119435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; omg come cuddle me i'm so sad that i can't go (</th>\n",
       "      <td>-4.097499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; that's so sad ( i'm sorry !</th>\n",
       "      <td>-4.062759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; wahhh i miss you more ( we haven't talked in forever . so sad</th>\n",
       "      <td>-3.996591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; when will you notice me ? i'm so sad (</th>\n",
       "      <td>-3.996374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miss my bed .. wish i was home (</th>\n",
       "      <td>-3.946296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    coefficient  label\n",
       "tweet                                                                 \n",
       "really sad i had to miss the #gsqaud game (           -4.745569      0\n",
       "it's cold in here ( ( and i'm all alone ( ( i'm...    -4.489991      0\n",
       "ughh i hate this (                                    -4.317277      0\n",
       "i miss this (                                         -4.144280      0\n",
       "rt <user> ( ( ( sad until cannot sad fml              -4.119435      0\n",
       "<user> omg come cuddle me i'm so sad that i can...    -4.097499      0\n",
       "<user> that's so sad ( i'm sorry !                    -4.062759      0\n",
       "<user> wahhh i miss you more ( we haven't talke...    -3.996591      0\n",
       "<user> when will you notice me ? i'm so sad (         -3.996374      0\n",
       "miss my bed .. wish i was home (                      -3.946296      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident correct predictions of negative tweets'.format(n_))\n",
    "df.query('label == 0').sort_values(by= 'coefficient', ascending = True).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most confident incorrect predictions of negative tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks )</th>\n",
       "      <td>3.272382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; )</th>\n",
       "      <td>3.103269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey &lt;user&gt; thanks for the ff . happy friday )</th>\n",
       "      <td>2.817429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; happy birthday to him of course )</th>\n",
       "      <td>2.459054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; thanks megan ! ) x</th>\n",
       "      <td>2.382431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; stoppostingpictureswiththatdeliciouscupcakeoriwilllbiteyoubecauseitlookssoawesomeandiwanttoeatit</th>\n",
       "      <td>2.341095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; #dunnowhereuare</th>\n",
       "      <td>2.341095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mishing &lt;user&gt;</th>\n",
       "      <td>2.341095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt;</th>\n",
       "      <td>2.341095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;user&gt; twitteameee</th>\n",
       "      <td>2.341095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    coefficient  label\n",
       "tweet                                                                 \n",
       "<user> thanks )                                        3.272382      0\n",
       "<user> )                                               3.103269      0\n",
       "hey <user> thanks for the ff . happy friday )          2.817429      0\n",
       "<user> happy birthday to him of course )               2.459054      0\n",
       "<user> thanks megan ! ) x                              2.382431      0\n",
       "<user> stoppostingpictureswiththatdeliciouscupc...     2.341095      0\n",
       "<user> #dunnowhereuare                                 2.341095      0\n",
       "mishing <user>                                         2.341095      0\n",
       "<user>                                                 2.341095      0\n",
       "<user> twitteameee                                     2.341095      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('{:d} most confident incorrect predictions of negative tweets'.format(n_))\n",
    "df.query('label == 0').sort_values(by= 'coefficient', ascending = False).head(n_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 86.35% / validation set: 81.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "mdb = MultinomialNB()\n",
    "mdb.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(mdb, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 80.62% / validation set: 75.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 80.62% / validation set: 75.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 78.49% / validation set: 78.48%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf =  linear_model.SGDClassifier(loss = 'log', max_iter=int(1e7), tol=1e-5, verbose = False)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 96.80% / validation set: 81.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf =  linear_model.Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 397. MiB for an array with shape (52029241,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c8902cf2cb1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             )\n\u001b[1;32m--> 303\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    304\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         array = _ensure_sparse_format(array, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    576\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;31m# create new with correct sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mspmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m             \u001b[0mchanged_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[1;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         csr_tocsc(self.shape[0], self.shape[1],\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 397. MiB for an array with shape (52029241,) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "helpers.judge_pred(clf, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 86.68%\n"
     ]
    }
   ],
   "source": [
    "# Prepare test set\n",
    "test_tweets = []\n",
    "with open('twitter-datasets/test_data.txt', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        sp = line.split(',')\n",
    "        index = sp[0]\n",
    "        test_tweets.append(','.join(sp[1:]))\n",
    "        \n",
    "# Compute tf-idf on full training set      \n",
    "X_train_final = tfidf_vectorizer.fit_transform(all_tweets)\n",
    "X_test = tfidf_vectorizer.transform(test_tweets)\n",
    "\n",
    "# Check training accuracy\n",
    "clf = LinearSVC(random_state=0, tol=1e-9, loss = 'squared_hinge', dual = True, C = 0.03)\n",
    "clf.fit(X_train_final, y)\n",
    "\n",
    "train_acc = (clf.predict(X_train_final) == y).mean()\n",
    "print('Training set accuracy: {:.2f}%'.format(100*train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save predictions\n",
    "save_filename = 'submissions/submission_tfidf.csv'\n",
    "predictions = clf.predict(X_test)\n",
    "helpers.save_pred(save_filename, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embeddings/tfidf_unique_full_train.npy', X_train_final)\n",
    "np.save('embeddings/tfidf_unique_full_labels.npy', y)\n",
    "np.save('embeddings/tfidf_unique_full_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.load('embeddings/tfidf_unique_full_train.npy', allow_pickle = True)\n",
    "y = np.load('embeddings/tfidf_unique_full_labels.npy', allow_pickle = True)\n",
    "X_test = np.load('embeddings/tfidf_unique_full_test.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
