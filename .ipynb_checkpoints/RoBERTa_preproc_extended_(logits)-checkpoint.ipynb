{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3LAcQ5NwOXR"
   },
   "source": [
    "Inspired by https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiC8CffiJHCT"
   },
   "source": [
    "### Main features\n",
    " 1. RoBERTa + Dropout + Linear\n",
    " 2. CrossEntropy Loss\n",
    " 3. Finetuning RoBERTa\n",
    " 3. Adam with Weight decay optimizer (cite this: https://arxiv.org/abs/1711.05101)\n",
    " 4. Cosine schedule\n",
    " 5. Preprocessing ('standard' or 'extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zyuAMjiwYmf",
    "outputId": "4f438035-fb97-4bda-b743-dba4e4a9777d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install wordsegment\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YxF7HI1W4u3v"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ray.tune in ray > 0.7.5 requires 'tabulate'. Please re-run 'pip install ray[tune]' or 'pip install ray[rllib]'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/ray/tune/progress_reporter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-06fab7fffb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_cosine_schedule_with_warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_pt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_ray_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_azureml_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/ray/tune/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_runner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwith_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyncer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSyncConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_trainable_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyncer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait_for_sync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_sync_periods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_runner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrialRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_reporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIReporter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJupyterNotebookReporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedulers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFIFOScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoopStopper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_reporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrial_progress_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mray_trial_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRayTrialExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m from ray.tune.result import (TIME_THIS_ITER_S, RESULT_DUPLICATE,\n",
      "\u001b[0;32m~/ml/ml-proj/lib/python3.6/site-packages/ray/tune/progress_reporter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     raise ImportError(\"ray.tune in ray > 0.7.5 requires 'tabulate'. \"\n\u001b[0m\u001b[1;32m     24\u001b[0m                       \u001b[0;34m\"Please re-run 'pip install ray[tune]' or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \"'pip install ray[rllib]'.\")\n",
      "\u001b[0;31mImportError\u001b[0m: ray.tune in ray > 0.7.5 requires 'tabulate'. Please re-run 'pip install ray[tune]' or 'pip install ray[rllib]'."
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, RobertaForSequenceClassification, AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sDBG-UenSK48"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aa9b0a3e2594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-BrK3x_E1CzH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from typing import Callable, List, Optional, Tuple\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imsUgzFRwLAI",
    "outputId": "7eaa3491-0c18-46e5-e406-ed30aab153b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/matteopariset/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/matteopariset/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7OgJPTFLz-T"
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAJTLBDS44VS",
    "outputId": "ee62d12c-b8df-4125-a6ad-a7cb3f0e1016",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5b6feb849048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roberta-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Hfg5tryRiEn"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.add_prefix_space = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7VzF_gAP3sM",
    "outputId": "a8937d05-4463-41c7-b74d-e22198aad23c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eb44337bab82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trying tokenizer:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"that's a #verybad sentence <user> <url> youre gonna love it. lemme know what u think :-/\"\n",
    "print(\"Trying tokenizer:\", bert_tokenizer.tokenize(\" \".join(process_sentence(sample_sentence.split(\" \"), standard_pipeline))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMkwtsSC6Csd",
    "outputId": "9f557d94-8de3-4392-a6f9-3b7041cea004"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/matteopariset/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /home/matteopariset/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i2XefgNT1JVp"
   },
   "outputs": [],
   "source": [
    "class RobertaSimple(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_model\n",
    "    ):\n",
    "        super(RobertaSimple, self).__init__()\n",
    "        self.model = bert_model\n",
    "\n",
    "    def forward(self, input_ids, input_attention, labels):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=input_attention, labels=labels)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xYV2iQDwvtxt"
   },
   "outputs": [],
   "source": [
    "def apply_preprocessing(tweet):\n",
    "    return \" \".join(process_sentence(tweet.split(\" \"), standard_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LXPyUFiIwLAJ"
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, chunks, labels, tokenizer, max_len):\n",
    "        self.chunks = chunks\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.chunks.shape[0]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.chunks[item]\n",
    "        labels = self.labels[item]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            apply_preprocessing(sentence),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SmJeHXSIL3sU"
   },
   "outputs": [],
   "source": [
    "rng = RandomState(124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlMYxKEh36ic"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Du8OPNMP7Px_"
   },
   "outputs": [],
   "source": [
    "# Download negative small\n",
    "# !wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQyeURtYWFXMzZoMnVEeGc_ZT1IMnhQ/root/content -O neg_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3M3JP-E17SpL"
   },
   "outputs": [],
   "source": [
    "# Download positive small\n",
    "# !wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQxYUNPOENKdTBrX19hY2c_ZT1WNW5Y/root/content -O pos_small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBdqRehYk95m",
    "outputId": "bd36faaf-cd28-4a2c-c960-135e7a13285e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-08 23:03:03--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQ0eDZMdDI5WXBlVXYyZGc_ZT1ZZDJn/root/content\n",
      "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
      "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://d6fldw.db.files.1drv.com/y4mT677vxr3BV8LZI_OqX1DbpwG5d-npIsv2PqEvg4r49RqRI9-QE__dsFsHCdTdnNP-IkyKZpesyPoVdD_kAWg6MQzntgpFWy1saRspUrpOnctnGcSlvikJjOFHtMM8laRD96sUbU0t_1sPyMUHjdAD1iy2w7_TLMAX3ig614_7AkB-b2utLC3cHtP0X4uier5OGQv-NqKuA8ZPUODIjN0vw/train_neg_full_u.txt [following]\n",
      "--2020-12-08 23:03:03--  https://d6fldw.db.files.1drv.com/y4mT677vxr3BV8LZI_OqX1DbpwG5d-npIsv2PqEvg4r49RqRI9-QE__dsFsHCdTdnNP-IkyKZpesyPoVdD_kAWg6MQzntgpFWy1saRspUrpOnctnGcSlvikJjOFHtMM8laRD96sUbU0t_1sPyMUHjdAD1iy2w7_TLMAX3ig614_7AkB-b2utLC3cHtP0X4uier5OGQv-NqKuA8ZPUODIjN0vw/train_neg_full_u.txt\n",
      "Resolving d6fldw.db.files.1drv.com (d6fldw.db.files.1drv.com)... 13.107.42.12\n",
      "Connecting to d6fldw.db.files.1drv.com (d6fldw.db.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 96050024 (92M) [text/plain]\n",
      "Saving to: ‘neg_full.txt’\n",
      "\n",
      "neg_full.txt        100%[===================>]  91.60M  13.3MB/s    in 6.9s    \n",
      "\n",
      "2020-12-08 23:03:10 (13.3 MB/s) - ‘neg_full.txt’ saved [96050024/96050024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download negative full\n",
    "!wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQ0eDZMdDI5WXBlVXYyZGc_ZT1ZZDJn/root/content -O neg_full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V42-UlNGVwaL",
    "outputId": "5b62fad0-cac6-4be3-d32f-e827319c6aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-08 23:03:11--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQzcTc3QmNPbUdIWHQ3TXc_ZT01ejdG/root/content\n",
      "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
      "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://pknvjw.db.files.1drv.com/y4mB6CuxdVyCAa1f_jeMpRk339mvvQqxnZRyH6_43ppSYfXDvaPBdmK92XPj-ptktso47h95B_PKWCJw0Yy5yxj6_pF5I5eRggN0bTDBdc9NkAGry8mcM3jdkFMlp4TRx76UK-2-KMAMX2cG5Hmi9tKLomHJrTrQ1WfC6KoqiueRMA_-IcQZIFUYbsBWxGJiM16U5uTVSurs_j8ejysi5y-vw/train_pos_full_u.txt [following]\n",
      "--2020-12-08 23:03:11--  https://pknvjw.db.files.1drv.com/y4mB6CuxdVyCAa1f_jeMpRk339mvvQqxnZRyH6_43ppSYfXDvaPBdmK92XPj-ptktso47h95B_PKWCJw0Yy5yxj6_pF5I5eRggN0bTDBdc9NkAGry8mcM3jdkFMlp4TRx76UK-2-KMAMX2cG5Hmi9tKLomHJrTrQ1WfC6KoqiueRMA_-IcQZIFUYbsBWxGJiM16U5uTVSurs_j8ejysi5y-vw/train_pos_full_u.txt\n",
      "Resolving pknvjw.db.files.1drv.com (pknvjw.db.files.1drv.com)... 13.107.42.12\n",
      "Connecting to pknvjw.db.files.1drv.com (pknvjw.db.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 78157401 (75M) [text/plain]\n",
      "Saving to: ‘pos_full.txt’\n",
      "\n",
      "pos_full.txt        100%[===================>]  74.54M  23.5MB/s    in 3.2s    \n",
      "\n",
      "2020-12-08 23:03:15 (23.5 MB/s) - ‘pos_full.txt’ saved [78157401/78157401]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download positive full\n",
    "!wget https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDQzcTc3QmNPbUdIWHQ3TXc_ZT01ejdG/root/content -O pos_full.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X6v4fUY04WjI"
   },
   "outputs": [],
   "source": [
    "neg_train = []\n",
    "with open(\"neg_full.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        neg_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "c4rsAd4MD0j8"
   },
   "outputs": [],
   "source": [
    "pos_train = []\n",
    "with open(\"pos_full.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        pos_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9Ik30qoDTZB",
    "outputId": "5fc058ce-2f79-4f77-b1eb-d2c23234e64d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: \t negative 1142838 \t positive 1127644\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size: \\t negative %d \\t positive %d\" % (len(neg_train), len(pos_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5xR1ZKpwLAK"
   },
   "source": [
    "## WARNING: I get rid of some negative samples to re-establish class equilibrium\n",
    "Imbalanced classes are a pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5CbPADOlwLAK"
   },
   "outputs": [],
   "source": [
    "if len(neg_train) < len(pos_train):\n",
    "  pos_train = neg_train[:len(neg_train)-len(pos_train)]\n",
    "elif len(neg_train) > len(pos_train):\n",
    "  neg_train = neg_train[:len(pos_train)-len(neg_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "brgye2sqwLAK"
   },
   "outputs": [],
   "source": [
    "assert len(neg_train) == len(pos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkTtCLBmxStp"
   },
   "source": [
    "#### Trim the dataset used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8W2gXvm0xeHh"
   },
   "outputs": [],
   "source": [
    "samples_num_by_cat = 1_120_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "euNoeET9e07T"
   },
   "outputs": [],
   "source": [
    "neg_train = neg_train[:samples_num_by_cat]\n",
    "pos_train = pos_train[:samples_num_by_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cmmBj-UpHL8s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([[0] * len(neg_train), [1] * len(pos_train)])\n",
    "\n",
    "train_data = np.concatenate([neg_train, pos_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZlpxdtqK_tu",
    "outputId": "ede8eb90-2273-4d92-f9e1-c1389b9ef1f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2240000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffling = np.arange(0, train_data.shape[0])\n",
    "len(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CmBQ5G89L8-G"
   },
   "outputs": [],
   "source": [
    "rng.shuffle(shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lmgYUmgbMAFZ"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[shuffling]\n",
    "train_data = train_data[shuffling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZWehjwewLAK",
    "outputId": "b26d5bb9-597c-427c-9e1c-cd291f6e4dc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'train', 'train', ..., 'train', 'train', 'train'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = rng.choice(\n",
    "    [\"train\", \"val\"],\n",
    "    size=len(train_data),\n",
    "    p=[.9, .1]\n",
    ")\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1h0aitnpEhVM"
   },
   "outputs": [],
   "source": [
    "bert_x_data = train_data[split == \"train\"]\n",
    "bert_labels = train_labels[split == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8kERT15OwLAK"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aKkzosniwLAK"
   },
   "outputs": [],
   "source": [
    "def get_loader(dataset):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "JndebrhSwLAK"
   },
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(\n",
    "    train_data[split == \"train\"], \n",
    "    train_labels[split == \"train\"], \n",
    "    tokenizer=bert_tokenizer, \n",
    "    max_len=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Se0EREarwLAK"
   },
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqQwAI0mwLAK",
    "outputId": "f67abf48-243c-45b0-fbaf-941781b432b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   611,  7474,  1855,  7474,  1855,  7474,   132, 39542,   359,\n",
       "           155,   475,   282, 15561,   536,    79,    26,    79,   473,    45,\n",
       "           283,   885,  1589,   143, 26848,  2407,  3999,  1942,    69, 13561,\n",
       "           438,   939,    74,   202,   236,   132,   428,   176,  6460,  1843,\n",
       "           306,  3623,   338, 28696,  6423, 15698,     2,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPni6FSWwLAK",
    "outputId": "6f7812ec-6aca-4ccd-9341-1b3b3518d8d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015851"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fAL6TM_A1o7x"
   },
   "outputs": [],
   "source": [
    "val_dataset = SentimentDataset(\n",
    "    train_data[split == \"val\"], \n",
    "    train_labels[split == \"val\"], \n",
    "    tokenizer=bert_tokenizer, \n",
    "    max_len=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "wKXvjfB61ym-"
   },
   "outputs": [],
   "source": [
    "val_loader = get_loader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nswta0AC16pQ",
    "outputId": "cd3ddd7a-a6c7-4203-bc30-f36970621b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224149"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd-06Pm13-gQ"
   },
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oktiMN3Nx0i",
    "outputId": "765d1d28-4c8e-4c82-dbe3-c36db1834448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected: _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU detected:\", torch.cuda.get_device_properties('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "bAqP1P-vwLAL"
   },
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "C15qcgvL1vd2"
   },
   "outputs": [],
   "source": [
    "bert_classification = RobertaSimple(bert_model)\n",
    "bert_classification = bert_classification.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "SSZXnB75wLAL"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "3u4ufnwdwLAL",
    "outputId": "c05c7b8d-02b0-4fb8-d00d-71f4d08ea516"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9381ec94a79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtot_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_classification' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(bert_classification.parameters(), lr=2e-5, correct_bias=False)\n",
    "tot_steps = EPOCHS * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ODGBQJOwLAL"
   },
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=tot_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "1yvejQO2wLAL"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                input_attention=attention_mask,\n",
    "                labels=targets\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            num_preds += targets.shape[0]\n",
    "            losses.append(loss.item())\n",
    "    return correct_predictions.double() / float(num_preds), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "9iSeuiZ2wLAL"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"labels\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      input_attention=attention_mask,\n",
    "      labels=targets\n",
    "    )\n",
    "\n",
    "    logits = outputs.logits\n",
    "    loss = outputs.loss\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "M5J49r7oAEGi"
   },
   "outputs": [],
   "source": [
    "def save_model(filename, model):\n",
    "    torch.save(model.state_dict(), filename + \".pth\")\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpzpUYTdzn_z",
    "outputId": "fc990409-30dc-46aa-a955-dbcb85538470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0\n",
      "\t Train:  (tensor(0.8844, device='cuda:0', dtype=torch.float64), 0.2703242950417377)\n",
      "\t Validation:  (tensor(0.9015, device='cuda:0', dtype=torch.float64), 0.24347110731848282)\n",
      "Model saved\n",
      "EPOCH:  1\n",
      "\t Train:  (tensor(0.9226, device='cuda:0', dtype=torch.float64), 0.1919433712967568)\n",
      "\t Validation:  (tensor(0.9064, device='cuda:0', dtype=torch.float64), 0.247945890677116)\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "for epch in range(EPOCHS):\n",
    "  print(\"EPOCH: \", epch)\n",
    "  print(\"\\t Train: \", train_epoch(bert_classification, train_loader, optimizer, gpu, scheduler, len(train_dataset)))\n",
    "  print(\"\\t Validation: \", eval_model(bert_classification, val_loader, gpu))\n",
    "  save_model(\"RoBERTa_preproc_\" + str(epch) + \"epch\", bert_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDkgWaGL1R95",
    "outputId": "7e662867-e32c-48fe-9fbb-e6c5c1e0b8eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8698, device='cuda:0', dtype=torch.float64), 0.3341606027943599)"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(bert_classification, all_neg_loader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VkrNc2F67MF"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "8PGctkhA6lXj"
   },
   "outputs": [],
   "source": [
    "# !onelink() { echo -n \"$1\"|base64|sed \"s/=$//;s/\\//\\_/g;s/\\+/\\-/g;s/^/https:\\/\\/api\\.onedrive\\.com\\/v1\\.0\\/shares\\/u\\!/;s/$/\\/root\\/content/\"; }; onelink \"https://1drv.ms/t/s!ArTDgu9z7IOVjp4yCxhYs8OaIwRKzw?e=aIxt9i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBPSdR2e7Dba",
    "outputId": "b02db34e-085f-4a7c-ef53-cb7e0f898832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-08 21:03:39--  https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content\n",
      "Resolving api.onedrive.com (api.onedrive.com)... 13.107.42.12\n",
      "Connecting to api.onedrive.com (api.onedrive.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://43loag.db.files.1drv.com/y4mXjx_iztEzPDr2_yEraDIdBKOZgu7urAv8l930TMSuHIzGvuuFoS5EfKK4GgVbyI14jS0zrrS931mmVdpBJy7ijfAC-JdaNmzUA6UaAGlRPgFHOMpuv1AGSx8mXlfcvy3wvWFXD_SU74GTlcsVczeKhgAYKm143iI_FhQ3xJt4LHHaGElsHNgoLfjIrFmv55BCkb-Wn44B_ej_zp_5Xu4yg/test_data.txt [following]\n",
      "--2020-12-08 21:03:39--  https://43loag.db.files.1drv.com/y4mXjx_iztEzPDr2_yEraDIdBKOZgu7urAv8l930TMSuHIzGvuuFoS5EfKK4GgVbyI14jS0zrrS931mmVdpBJy7ijfAC-JdaNmzUA6UaAGlRPgFHOMpuv1AGSx8mXlfcvy3wvWFXD_SU74GTlcsVczeKhgAYKm143iI_FhQ3xJt4LHHaGElsHNgoLfjIrFmv55BCkb-Wn44B_ej_zp_5Xu4yg/test_data.txt\n",
      "Resolving 43loag.db.files.1drv.com (43loag.db.files.1drv.com)... 13.107.42.12\n",
      "Connecting to 43loag.db.files.1drv.com (43loag.db.files.1drv.com)|13.107.42.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 817297 (798K) [text/plain]\n",
      "Saving to: ‘test_data.txt’\n",
      "\n",
      "test_data.txt       100%[===================>] 798.14K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-12-08 21:03:39 (18.6 MB/s) - ‘test_data.txt’ saved [817297/817297]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O test_data.txt https://api.onedrive.com/v1.0/shares/u!aHR0cHM6Ly8xZHJ2Lm1zL3QvcyFBclREZ3U5ejdJT1ZqcDR5Q3hoWXM4T2FJd1JLenc_ZT1hSXh0/root/content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6fOi2cxc793I"
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "\n",
    "    idxs = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            idx = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                input_attention=attention_mask,\n",
    "                labels=torch.zeros(idx.shape[0], dtype=torch.long).to(device),\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            idxs.append(idx.cpu())\n",
    "            predictions.append(preds.cpu())\n",
    "\n",
    "    return np.concatenate(idxs), np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "k4MB7sZQ6b7j"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(model, device):\n",
    "    print(\"Loading file...\")\n",
    "    unk_ids = []\n",
    "    unk_data = []\n",
    "    with open(\"test_data.txt\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            comma_pos = line.find(\",\")\n",
    "            unk_ids.append(int(line[:comma_pos]))\n",
    "            unk_data.append(line[comma_pos+1:])\n",
    "            \n",
    "    # Sanity check\n",
    "    assert len(unk_data) == 10000\n",
    "\n",
    "    print(\"Content:\", unk_ids[:2], unk_data[:2])\n",
    "    \n",
    "    print(\"Create dataloader...\")\n",
    "    dataset = SentimentDataset(\n",
    "        np.array(unk_data), \n",
    "        np.array(unk_ids), \n",
    "        tokenizer=bert_tokenizer, \n",
    "        max_len=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    d_loader = get_loader(dataset)\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    return predict(model, d_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMwOMNVK9Szb",
    "outputId": "6d90b2cf-7936-421f-814f-cfd259566a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Content: [1, 2] ['sea doo pro sea scooter ( sports with the portable sea-doo seascootersave air , stay longer in the water and ... <url>\\n', \"<user> shucks well i work all week so now i can't come cheer you on ! oh and put those batteries in your calculator ! ! !\\n\"]\n",
      "Create dataloader...\n",
      "Generating predictions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([    1,     2,     3, ...,  9998,  9999, 10000]),\n",
       " array([0, 0, 0, ..., 0, 1, 0]))"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_idxs, submission_labels = prepare_submission(bert_classification, gpu)\n",
    "submission_idxs, submission_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDOAMAo2N-hn",
    "outputId": "19715768-d180-47f3-fefa-14d0bd40e760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_labels.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4ldN_1zY-3Ez"
   },
   "outputs": [],
   "source": [
    "def write_submission(filename, idxs, labels):\n",
    "  # Convert to -1, 11\n",
    "  labels = (labels * 2 - 1).astype(int)\n",
    "  idxs = idxs.astype(int)\n",
    "  submission_content = np.concatenate([idxs[..., np.newaxis], labels[..., np.newaxis]], axis=1).astype(int)\n",
    "  print(submission_content)\n",
    "  np.savetxt(filename, submission_content, fmt='%d', delimiter=',', header=\"Id,Prediction\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRGSxy_B_5Uj",
    "outputId": "704cee16-99bf-49cf-a8d9-500eef60d4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    -1]\n",
      " [    2    -1]\n",
      " [    3    -1]\n",
      " ...\n",
      " [ 9998    -1]\n",
      " [ 9999     1]\n",
      " [10000    -1]]\n"
     ]
    }
   ],
   "source": [
    "write_submission(\"sub_preproc.csv\", submission_idxs, submission_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WSB09r6zE20i"
   },
   "outputs": [],
   "source": [
    "# Not yet tested\n",
    "def load_model(filename, bert_model, device):\n",
    "    model = RobertaSimple(bert_model)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(filename + \".pth\"))\n",
    "    model.eval()\n",
    "    print(\"Model loaded\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "tuX7jBHWErS6",
    "outputId": "1fe6d961-ad65-4bd9-de67-bedcd9919c32"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-60f208882b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sub2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_classification' is not defined"
     ]
    }
   ],
   "source": [
    "# save_model(\"sub2\", bert_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "AlxKidneT3od"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "reloaded_model = load_model(\"RoBERTa_preproc_std_0epch\", bert_model, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyeF0Fh2Ud8A",
    "outputId": "00c8fc8d-2c48-4201-e940-7a2b08af601f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Content: [1, 2] ['sea doo pro sea scooter ( sports with the portable sea-doo seascootersave air , stay longer in the water and ... <url>\\n', \"<user> shucks well i work all week so now i can't come cheer you on ! oh and put those batteries in your calculator ! ! !\\n\"]\n",
      "Create dataloader...\n",
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "_, reloaded_preds = prepare_submission(reloaded_model, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFVsREvjUrsy",
    "outputId": "ced77670-f159-42bb-928b-d60f8881761e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5035"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_preds.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhCZKb9xYBbz",
    "outputId": "06114f29-8203-43e7-d463-846264230074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    -1]\n",
      " [    2    -1]\n",
      " [    3     1]\n",
      " ...\n",
      " [ 9998    -1]\n",
      " [ 9999     1]\n",
      " [10000    -1]]\n"
     ]
    }
   ],
   "source": [
    "write_submission(\"RoBERTa_std_epch0.csv\", np.arange(1, 10001, 1), reloaded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lOgnhLwsrUh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RoBERTa_preproc_Tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
